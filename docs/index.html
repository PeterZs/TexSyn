<!DOCTYPE html><html>  <head>    <meta http-equiv="content-type" content="text/html; charset=UTF-8">    <title>TexSyn</title>    <!-- <style type="text/css"> #backbg { background-color: gray; }      </style>		-->    <style>			body {             background-color: gray;             font-family: Arial, Helvetica, sans-serif;           }      h1 { padding: 0; border: 0; margin: 0; margin-top: 0.2em; }      h2 { padding: 0; border: 0; margin: 0; margin-top: 0.2em; }      p { color: black; }      code { font-size: 120%; }      pre {            color: white;	          border: 1px dashed rgb(65%,65%,65%);	          padding: 10px;           	margin-bottom: 1em;          }      .comment { color: rgb(80%,80%,80%); }      <!-- for in-page date anchors -->      a.date         {color: white; }			a.date:link    {text-decoration: none; color: white;}			a.date:visited {text-decoration: none; color: white;}			a.date:hover   {text-decoration: underline; color: white;}			a.date:active  {text-decoration: none; color: white;}      .post {              border-top: 0.3em solid rgb(25%,25%,25%);              margin-top: 1em;              padding-left: 2em;              padding-right: 2em;              padding-top: 1em;              clear: left ;            }      .designnote { color: rgb(25%,25%,25%) }            .novak_pad { margin-right: 105px; margin-left: 105px; }      <!-- --------------------------------------------------------------------------- -->      <div class="post" id="yyyymmdd">        <a href="#yyyymmdd" class="date">Month 0, 0000</a>        <h1>Title</h1>        <p>...</p>        <pre>x</pre>        <img src="images/xxx" alt="" title="" height="511" width="511">      </div>      <!-- --------------------------------------------------------------------------- -->    </style>  </head>  <body>    <div style="font-size:75%;"> <a href="https://cwreynolds.github.io/TexSyn/">This
        page on GitHub</a> </div>    <h1>Introduction</h1>    <br>    <p><strong>TexSyn</strong> is an idiosyncratic library for procedural      texture synthesis. It is not intended for use “by human hands.” TexSyn      programs will be automatically generated with a Genetic Programming      system. This is a blog (or a lab notebook? a design diary?) about making      TexSyn. It is not proper documentation, although might be some sort of a      starting point. Mostly this describes in “blog order” the steps and design      decisions made in its construction. There is some background and      introductory information, at the bottom of this page, in the entry for <a        href="#20191215">December
        15, 2019</a>.</p>    <br style="--------------------------------------------------------------------------">    <div class="post" id="20200502"> <a href="#20200502" class="date">May 2,        2020</a>      <h1>Interpolate and blur colors in RGB space with linear gamma.</h1>      <p><strong>Or: “I finally know how to fix that bug from 1982.”</strong></p>      <p>While working on the <em>Gamma</em> texture operator (<a href="#20200426">April
          26</a>) I was reading background material on the topic of gamma        correction. It comes up a lot in computer graphics and digital image        processing. In the back of my mind I knew gamma was important for        correct and efficient image representation, and as a tool for adjusting        the tone/contrast of an image. But it is also key to getting image        blending and anti-aliasing to work correctly. I was looking at John        Novak's 2016 “What Every Coder Should Know About Gamma” and was struck        by the section on “<a href="https://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/">colour
          blending</a>” — particularly Figure 8:</p>      <img src="images/Novak_gamma_blend_bad.png" alt="Figure 8b from John Novak's 2016 “What Every Coder Should Know About Gamma”"        title="Figure 8b from John Novak's 2016 “What Every Coder Should Know About Gamma”"        class="novak_pad"        height="227"        width="300">      <img src="images/Novak_gamma_blend_good.png" alt="Figure 8b from John Novak's 2016 “What Every Coder Should Know About Gamma”"        title="Figure 8a from John Novak's 2016 “What Every Coder Should Know About Gamma”"        class="novak_pad"        height="227"        width="300">      <p>I recreated a bit of it in the first texture below. There are red and        magenta spots composited with <em>SoftMatte</em> onto a green        background<em></em>. The two spots have an obviously incorrect dark ring        around them. I had been seeing—and willfully ignoring—this artifact in        TexSyn. But seeing this test, my mind went back to my early days at SGD,        the graphics “division” of Symbolics Inc. Around 1982 my first big        project was an interactive “paint” system for graphics and illustration.        I noticed these annoying dark boundaries when certain color pairs were        blended together. I had several theories for what caused the problem but        none of them was <strong>gamma</strong>. Novak's Figure 8 grabbed my        attention because it clearly showed the problem, and showed how it        should look when the problem is solved.</p>      <p>The <em>Spot</em> texture generator uses a sinusoidal transition from        the outside color (at 0) to the inside color (at 1). That blend factor        “alpha” is then used for a simple linear interpolation between the        colors. But “linear interpolation” assumes a linear space. Color values        as displayed on the screen assume a gamma of about 2.2. (Of course it is        more complicated, the color space definition is: <a href="https://en.wikipedia.org/wiki/Gamma_correction#Microsoft_Windows,_Mac,_sRGB_and_TV/video_standard_gammas">sRGB</a>.)
        In order to perform linear interpolation of color values requires the        RGB components be “de-gamma-ed” into linear space before interpolation,        and “re-gamma-ed” afterward. TexSyn's <code>interpolate()</code>        function had been a simple C++ template compatible with all types. Now        there is a special case for interpolation of <code>Color</code> values.        Here is the original failing case and the improved version which        performs color interpolation in linear (gamma=1) space.</p>      <img src="images/20200501_two_spot_before.png" alt="" title="" height="511"        width="511">      <img src="images/20200501_two_spot_after.png" alt="" title="" height="511"        width="511">      <pre><span class="comment">// Texture above made from three Uniform textures of pure red, green and magenta:</span>red = Uniform(Color(1, 0, 0))green = Uniform(Color(0, 1, 0))magenta = Uniform(Color(1, 0, 1))<br><span class="comment">// A Spot, at origin, white within inner radius 0.1, blends to black at outer radius 0.5:</span><br>spot = Spot(Vec2(), 0.1, Color(1, 1, 1), 0.5, Color(0, 0, 0));<br><spanclass="comment">// The spot, shifted to left and right, to matte in red and magenta onto green:</span><br>two_spots = SoftMatte(Translate(Vec2(0.5, 0), spot)<br>                     &nbsp;SoftMatte(Translate(Vec2(-0.5, 0), spot), green, red),                      magenta)</pre>      <p>This is the second texture above with inner and outer radii for the two        <em> Spots</em> drawn in to help visualize where the color gradients        fall:</p>      <img src="images/20200501_two_spot_after_marked.png" alt="" title="" height="511"        width="511">      <p>The <em>SoftMatte</em> operator defines a texture that (for any given        location) uses the luminance of it first texture parameter (called        “matte”, here one of the two <em>Spot</em>s) to control the blend of        the other two input textures. It now performs a “de-gamma” on the        “matte” texture so that all three values involved in the interpolation        are in linear gamma RGB space.</p>      <p>Taken together, these changes (to <code>interpolate()</code> for <code>Color</code>        and the <em>SoftMatte</em> texture operator) handle most of the        blending gamma errors in the current library. Most operators rely on the        same <code>interpolate()</code> function. For example, here is a <em>LotsOfSpots</em>        before and after this change, for the problematic red and green color        combination:</p>      <pre>LotsOfSpots(0.9, 0.02, 0.5, 0.1, Color(1, 0, 0), Color(0, 1, 0))</pre>      <img src="images/20200501_LotsOfSpots_before.png" alt="" title="" height="511"        width="511">      <img src="images/20200501_LotsOfSpots_after.png" alt="" title="" height="511"        width="511">      <p>Another place where color computation require correct handling of gamma        is in the <em>Blur</em> low pass filter. (The <em>EdgeDetect</em> and        <em>EdgeEnhance</em> operators (see <a href="#20200301">March 1</a>)        are based on <em>Blur</em> and so inherit its functionality.) Shown        below is a test pattern <code>grating</code>, and two applications of <em>Blur</em>,        before and after this gamma change. As in the case of <em>SoftMatte</em>        and <code>interpolate()</code>, the change is basically to “de-gamma”        the color values before the convolution calculation, then to “re-gamma”        the resulting filtered value. (The Novak page cited above also links to        this page, by the late Ellie Stone, which has good example images of        blending and blurring: <a href="https://ninedegreesbelow.com/photography/linear-gamma-blur-normal-blend.html">Linear
          Gamma vs Higher Gamma RGB Color Spaces: Gaussian Blur and Normal Blend          Mode</a>.)</p>      <pre><span class="comment">// Define "grating". apply Blur with kernel width of 0.1</span>grating = Grating(Vec2(), Color(1, 1, 0), Vec2(0.2, 0), Color(0, 0, 1), 0.01);Blur(0.1, grating)</pre> <img src="images/20200501_Grating.png" alt="" title="" height="511" width="511">      <br>      <img src="images/20200501_Blur_Grating_before.png" alt="" title="" height="511"        width="511">      <br>      <img src="images/20200501_Blur_Grating_after.png" alt="" title="" height="511"        width="511">      <p>In the examples above, <code>grating</code> has 10 <strong>pairs</strong>        of yellow-blue stripes, so 20 individual stripes across its rendered        diameter of 2 units. Each (say) yellow stripe has a width of 0.1. We        then apply <em>Blur</em> to it with a kernel width of 0.1. So the        circular “support” of the filter kernel of a pixel centered on a yellow        stripe will all be yellow. It follows that a pixel centered on a (say)        yellow stripe should have a color identical to the corresponding place        on the original <code>grating</code> texture. (Conversely a pixel on        the boundary between yellow and blue will result in a blend of half        yellow and half blue.) This comparison can be seen in the image below. A        horizontal slice through the three textures above are juxtaposed so they        can be more carefully compared. Following the center line of a yellow        stripe, it appears to be the same color in all three, as intended.        Similarly for blue. What differs is the luminance of the blurred        transition between yellow and blue. With the old code (stripe 2 of 3        below) the transitions are too dark. (This recalls the dark rings around        the red and magenta spots in the first example above.) With the new code        (stripe 3 of 3 below) the transitions are brighter and seem to better        represent a transition from yellow to blue. Note that interpolating        between complementary color pairs (like yellow↔︎blue, magenta↔︎green, or        cyan↔︎red) requires traversing a main diagonal of the RGB color cube        between opposite corners. This causes the center of the interpolation        path to pass through the monochrome axis, the fourth main cube diagonal        between black and white. We see these grayish midrange colors here        between yellow and blue stripes, and in the first example above, between        a magenta spot and the green background.</p>      <img src="images/20200502_compare%20blurs.png" alt="" title="" height="125"        width="511">    </div>    <div class="post" id="20200426"> <a href="#20200426" class="date">April 26,        2020</a>      <h1><em>Gamma</em></h1>      <p><em>Gamma</em> provides the <a href="https://en.wikipedia.org/wiki/Gamma_correction">standard
          operation used in digital image processing</a>: exponentiating the RGB        components by a given parameter gamma (<em>γ</em>). Values other than 1        cause a nonlinear contrast mapping. When gamma is less than 1, mid-range        colors will be brighter. When gamma is greater than 1, mid-range colors        will be darker. Values near white (luma ~1) and near black (luma ~0)        stay about the same.</p>      <p>Note that <em>Gamma</em> and <em>AdjustBrightness</em> (see <a href="#20200304">March
          4</a>) are similar. Both have one float parameter and change a        texture's contrast. <em>AdjustBrightness</em> performs a linear scale        of a texture's brightness, so changes its contrast. Gamma makes a        nonlinear contrast change. Normally gamma correction is used on color        values within the positive unit RGB cube. In TexSyn colors are three        arbitrary floats. </p>      <p>Shown below are five applications of <em>Gamma</em> to the same <em>ColorNoise</em>        texture <code>cn</code>. The parameters are <strong>0.5</strong>, <strong>0.66</strong>,        <strong>1</strong>, <strong>1.5</strong>, <strong>2</strong>. I tested        that as intended, <code>Gamma(1, cn)</code> is identical to <code>cn</code>.</p>      <pre>cn = ColorNoise(0.3, Vec2(5, 3), 0.6)<br>Gamma(0.5, cn)</pre>      <img src="images/20200426_Gamma_0_50.png" alt="Gamma(0.5, cn)" title="Gamma(0.5, cn)"        height="511"        width="511">      <br>      <pre>Gamma(0.66, cn)</pre>      <img src="images/20200426_Gamma_0_66.png" alt="Gamma(0.66, cn)" title="Gamma(0.66, cn)"        height="511"        width="511">      <br>      <pre>Gamma(1, cn)  <span class="comment">// verified by Texture::diff() to be identical to "cn" </span></pre>      <img src="images/20200426_Gamma_1_00.png" alt="Gamma(1, cn)" title="Gamma(1, cn)"        height="511"        width="511">      <br>      <pre>Gamma(1.5, cn)</pre>      <img src="images/20200426_Gamma_1_50.png" alt="Gamma(1.5, cn)" title="Gamma(1.5, cn)"        height="511"        width="511">      <br>      <pre>Gamma(2, cn)</pre>      <img src="images/20200426_Gamma_2_00.png" alt="Gamma(2, cn)" title="Gamma(2, cn)"        height="511"        width="511">      <br>    </div>    <div class="post" id="20200421"> <a href="#20200421" class="date">April 21,        2020</a>      <h1>Even speedier <em>LotsOfSpots</em></h1>      <p>In the previous post, I clocked recent acceleration due to algorithmic        and parallelism as producing a speed-up of 17x. I tried one more time        today and got it to <strong>22 times faster</strong> than the April 7        version, as measured on the same test suite of six textures shown in the        previous post.</p>      <p>Part of this was due to what I think of as <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl's
          law</a>, or at least the underlying principle. On an ideally parallel        workload, execution time is inversely proportional to the number of        parallel processors applied to the task. But normally there is some        overhead that cannot be made parallel. That places a ceiling on the        speed-up. (E.G. if 5% of the task cannot be made parallel, it will never        run more that 20 times faster regardless of the number of processors        applied to the task.) In concrete terms, the function <code>LotsOfSpotsBase::adjustOverlappingSpots()</code>        was originally an O(<em>n²</em>) algorithm. Then using the <code>DiskOccupancyGrid</code>        spatial data structure reduced that to O(<em>n</em>). Then I        parallelized the part for deciding if each disk overlapped another, and        if so, computing the required move. Finally today I parallelized the        other part: erasing each disk from the grid, moving it, and reinserting        it into the grid. This required making <code>DiskOccupancyGrid</code>        thread-safe.</p>      <p>I also looked at the number of threads used. In rendering I use a        thread per scanline (row of pixels), so the renderings on this page use        about 500 threads. In my prototype “disk de-overlapping” code I had        arbitrarily selected 40 threads. I tested other values. It kept getting        faster as I reduced the number of threads, until it hit a minimum at 8        threads, then got slower as I used fewer threads. Coincidentally, there        are 8 hardware “hyperthreads” on the 4 cores of my laptop's CPU. I don't        know if if this is purely coincidental, but in case not, my thread count        is now set to the value returned by <code>std::thread::hardware_concurrency()</code>.      </p>    </div>    <div class="post" id="20200419"> <a href="#20200419" class="date">April 19,        2020</a>      <h1>Speed ups for <em>LotsOfSpots</em> and friends</h1>      <p>As mentioned on <a href="#20200406">April 6</a> the compute speed for        the base class for <em>LotsOfSpots</em>, etc. was much too slow. The        algorithm to ensure the “spots” did not overlap was O(<em>n</em>²) with        typical <em>n</em> being in the thousands (4264 spots in the first two        example below). I made two main changes. First to use a spatial data        structure to allow quickly finding “spots” near a given point in texture        space (for rendering) and near another spot to determine if they        overlap. The second change was to use multi-thread parallelism during        the overlap removal. Averaged over multiple runs, using the test suite        below (6 textures), the code now runs about <strong>17 times faster</strong>.        The images below show a sample <em>LotsOfSpots</em>, and then the same        texture “zoomed out” (scaled down by 0.13) to show the entire tiling        pattern. </p>      <p>To help compare these pair of images: the tiles are 10x10 texture space        units, meaning they are 5 times wider than the circular renderings whose        diameters are 2 units. The “close up” image corresponds to the very        center region of the zoomed out image next to it. You can see the scale        of the tiling pattern if you look closely at the zoomed out image. For        example, look at the second image: on the right hand side just below        center there is a “bare patch” with more magenta background and less        cyan spots. If you look to the left, about two third of the way across,        you can see the same bare patch repeated (see second image on <a href="#20200403">April
          3</a> which highlights the central tile).</p>      <pre><span class="comment">// ~70% of texture is covered by spots, radii range from 0.02 to 0.2</span>LotsOfSpots(0.7, 0.02, 0.2, 0.01, c, m)Scale(0.13, LotsOfSpots(0.7, 0.02, 0.2, 0.01, c, m))</pre>      <img src="images/20200419_los1.png" alt="LotsOfSpots(0.7, 0.02, 0.2, 0.01, c, m)"        title="LotsOfSpots(0.7, 0.02, 0.2, 0.01, c, m)"        height="511"        width="511">      <img src="images/20200419_los1_scaled.png" alt="Scale(0.13, LotsOfSpots(0.7, 0.02, 0.2, 0.01, c, m))"        title="Scale(0.13, LotsOfSpots(0.7, 0.02, 0.2, 0.01, c, m))"        height="511"        width="511">      <pre><span class="comment">// ~80% of texture is covered by spots, radii range from 0.02 to 0.4</span>LotsOfSpots(0.8, 0.02, 0.4, 0.02, c, m)Scale(0.13, LotsOfSpots(0.8, 0.02, 0.4, 0.02, c, m))</pre>      <img src="images/20200419_los2.png" alt="LotsOfSpots(0.8, 0.02, 0.4, 0.02, c, m)"        title="LotsOfSpots(0.8, 0.02, 0.4, 0.02, c, m)"        height="511"        width="511">      <img src="images/20200419_los2_scaled.png" alt="Scale(0.13, LotsOfSpots(0.8, 0.02, 0.4, 0.02, c, m))"        title="Scale(0.13, LotsOfSpots(0.8, 0.02, 0.4, 0.02, c, m))"        height="511"        width="511">      <pre><span class="comment">// ~80% of texture is covered by spots, all radii are 0.2</span>LotsOfSpots(0.8, 0.2, 0.2, 0.02, c, m)Scale(0.13, LotsOfSpots(0.8, 0.2, 0.2, 0.02, c, m))</pre>      <img src="images/20200419_los3.png" alt="LotsOfSpots(0.8, 0.2, 0.2, 0.02, c, m)"        title="LotsOfSpots(0.8, 0.2, 0.2, 0.02, c, m)"        height="511"        width="511">      <img src="images/20200419_los3_scaled.png" alt="Scale(0.13, LotsOfSpots(0.8, 0.2, 0.2, 0.02, c, m))"        title="Scale(0.13, LotsOfSpots(0.8, 0.2, 0.2, 0.02, c, m))"        height="511"        width="511">    </div>    <div class="post" id="20200407"> <a href="#20200407" class="date">April 7,        2020</a>      <h1>Even more <em>LotsOfButtons</em></h1>      <p>I had not tested <em>LotsOfButtons</em> with a non-zero <code>button_center</code>        parameter. Sure enough, it did not work correctly. I made a new test        case to use while fixing it. Here is contrived <code>button_texture</code>        called “<code>sixths</code>” whose edges cross at <code>Vec2(0.5, 0.5)</code>:</p>      <img src="images/20200407_sixths.png" alt="sixths" title="sixths" height="511"        width="511">      <p>Here is a <em>LotsOfButtons</em> using that <code>sixths</code> as        its <code>button_texture</code>, and a <code>button_center</code> of <code>Vec2(0.5,
          0.5)</code>. Now, after the bug fix, the six-fold input pattern is        correctly positioned inside each spot:</p>      <pre>LotsOfButtons(0.8, 0.04, 0.4, 0.02, Vec2(0.5, 0.5), sixths, 0, Color(0.3, 0.3, 0.3))</pre>      <img src="images/20200407_LotsOfButtons_offset.png" alt="LotsOfButtons offset"        title="LotsOfButtons offset"        height="511"        width="511">      <p>The spiral pattern in yesterday's tests largely masked the issue of        orientation. This highly directional texture makes it much more obvious        that all the “buttons” are in the same orientation. I'm sure there are        occasions when that could be helpful. Yet it feels oddly regular and        mechanical next to the randomized positions and sizes of the spots. So I        added code to randomly rotate each “button” as shown below. I added (yet        another!) parameter to select between random-rotate or not. Like the <code>which</code>        parameter to <em>MultiNoise</em> (see <a href="#20200112">January 12</a>)        it is given as a floating point value—which is interpreted as a Boolean        value via thresholding: (<code>button_random_rotate &gt; 0.5</code>)—allowing
        it to be changed by mutation in the course of a Genetic Programming run.        The operational principle being: “let evolution decide”!</p>      <pre>LotsOfButtons(0.8, 0.04, 0.4, 0.02, Vec2(0.5, 0.5), sixths, 1, Color(0.3, 0.3, 0.3))</pre>      <img src="images/20200408_LotsOfButtons_random_rotate.png" alt="LotsOfButtons random rotate"        title="LotsOfButtons random rotate"        height="511"        width="511">      <pre><span class="comment">// Just for completeness this is the "sixths" button_texture used above:</span>p1 = Vec2(-0.01, 0);p2 = Vec2(+0.01, 0);a3 = 2 * pi / 3;<br>sixths = Translate(Vec2(0.5, 0.5),                   Add(Gradation(p1.rotate(a3 * 2), Color(0.1, 0.1, 0.3),                                 p2.rotate(a3 * 2), Color(0.3, 0.3, 0.3)),                       Add(Gradation(p1.rotate(a3), Color(0.1, 0.3, 0.1),                                     p2.rotate(a3), Color(0.3, 0.3, 0.3)),                           Gradation(p1,            Color(0.3, 0.1, 0.1),                                     p2,            Color(0.3, 0.3, 0.3)))))</pre>    </div>    <div class="post" id="20200406c"> <a href="#20200406c" class="date">April        6, 2020</a>      <h1><em>LotsOfButtons</em></h1>      <p><em>LotsOfButtons</em> is another variation on <em>LotsOfSpots</em>        where the spots are filled with a circular portion of another texture.        (I am still considering the use of “button” to mean a little portion of        one texture inserted into another. Possible alternatives: thumbnail,        icon, crop, stamp (as in rubber-stamp, pretty archaic), cameo,        cookie...) </p>      <p>Shown below are two examples of parameters to <em>LotsOfButtons</em>,        and the texture used to fill the individual spots. The parameters to <em>LotsOfButtons</em>        is similar to <em>ColoredSpots</em> with the addition of a <em>Vec2</em>        position indicating the center of the input texture used for filling the        individual spots. I am undecided on whether it makes more sense for the        input <code>button_texture</code> should be scaled according to the        radius of a spot.</p>      <p>The fourth parameter to the <em>LotsOf</em>... operators—the <code>soft_edge_width</code>—had
        been handled incorrectly and is now fixed. I was constraining it to be        half the <code>min_radius</code>. First of all that should not have        been half (radius-diameter confusion) and secondly the constraint should        have been on a per-spot basis. That is: a large <code>soft_edge_width</code>        (indicating very fuzzy-edged spots) should be used as given for large        spots, and constrained only for individual spots whose radius was less        than <code>soft_edge_width</code>.</p>      <pre><span class="comment">// Parameters are: density, min_r, max_r, soft, button_center, button_texture, bg_color</span>LotsOfButtons(0.79, 0.1, 0.6, 0.05, Vec2(), twist, gray2)</pre>      <img src="images/20200406_LotsOfButtons_1.png" alt="LotsOfButtons_1" title="LotsOfButtons_1"        height="511"        width="511">      <pre>LotsOfButtons(0.6, 0.05, 0.25, 0.025, Vec2(), twist, gray2)</pre>      <img src="images/20200406_LotsOfButtons_2.png" alt="LotsOfButtons_2" title="LotsOfButtons_2"        height="511"        width="511">      <pre><span class="comment">// this is the input texture whose center is inserted into each spot above.</span>red = Color(1, 0, 0);gray2 = Color(0.2, 0.2, 0.2);gray3 = Color(0.3, 0.3, 0.3);twist = Twist(7, 9, Vec2(),              SliceToRadial(Vec2(0, 0.318), Vec2(),                            Grating(Vec2(0, -0.1), red,                                    Vec2(0, +0.1), gray3, 0.3)))</pre>      <img src="images/20200406_Twist.png" alt="Twist" title="Twist" height="511"        width="511">    </div>    <div class="post" id="20200406b"> <a href="#20200406b" class="date">April        6, 2020</a>      <h1><em>ColoredSpots</em></h1>      <p><em>ColoredSpots</em> is based on an experiment from <a href="http://www.red3d.com/cwr/texsyn/diary.html#20100209">February
          9, 2010</a>. It uses the same geometric model as <em>LotsOfSpots</em>,        then each spot's color is taken from a given <code>color_texture</code>.        Shown below is a <em>ColoredSpots</em> texture and the <em>ColorNoise</em>        from which its spot colors are taken. </p>      <p>To do this I refactored <em>LotsOfSpots</em> into a base class <em>LotsOfSpotsBase</em>,        then moved the two color version into a derived class (now called <em>LotsOfSpots</em>)        which inherits from the base class. Then I added a second derived class        <em>ColoredSpots</em> also inheriting from <em>LotsOfSpotsBase.</em></p>      <pre>cn = AdjustSaturation(1.2, ColorNoise(2.5, Vec2(3, 4), 0.2))Scale(0.2, ColoredSpots(0.5, 0.2, 0.3, 0.05, cn, gray50))</pre> <img src="images/20200406_ColoredSpots.png" alt="" title="" height="511"        width="511">      <img src="images/20200406_ColorNoise.png" alt="" title="" height="511" width="511">    </div>    <div class="post" id="20200406"> <a href="#20200406" class="date">April 6,        2020</a>      <h1>Preliminary post-prototype <em>LotsOfSpots</em></h1>      <p>So far the <em>LotsOfSpots</em> prototype had been black and white for        simplicity. I finally got around to adding color parameters for spots        and background. I'm planning some other varients on the basic concepts.        I also noticed that—without the <code>Scale(0.2, ...)</code> I'd been        wrapping them in—spot parameters that seem “reasonable” lead to        excessive initialization and rendering times. Worse than <em>Blur</em>        before I sped it up. So I will need to improve the algorithmic        performance of <em>LotsOfSpots</em>. For comparison, this texture,        without the scale, has 4264 spots per 10x10 tile, which is a big <em>n</em>        for O(<em>n</em>²) algorithms.</p>      <pre>c = Color(0.0, 0.8, 1.0)m = Color(0.8, 0.0, 0.8)LotsOfSpots(0.7, 0.02, 0.2, 0.01, c, m)</pre>      <img src="images/20200406_LotsOfSpots_with_color.png" alt="LotsOfSpots(0.7, 0.02, 0.2, 0.01, c, m)"        title="LotsOfSpots(0.7, 0.02, 0.2, 0.01, c, m)"        height="511"        width="511">    </div>    <div class="post" id="20200405"> <a href="#20200405" class="date">April 5,        2020</a>      <h1>Choosing spots for <em>LotsOfSpots</em></h1>      <p>I drilled down a bit into the generation of the “random” spots in the        prototype <em>LotsOfSpots</em> constructor. Below are three samples of        various settings of the parameters that control the placement of spots.        Those parameters are: <code>spot_density</code>, <code>min_radius</code>,        <code>max_radius</code>, and <code>soft_edge_width</code>. Some        constraints are enforced for practicality: <code>density</code> is        clipped to 1, <code>soft_edge_width</code> is clipped to half of <code>min_radius</code>.        The random radii fall between the min and max parameters, the the        selection is biased toward the smaller values. Each of these texture        samples are shown scaled down by a factor of 0.2, which means the whole        10x10 central tile is the bounding box of the circular texture. </p>      <p>In this first sample, the density is 0.5 so the total area of white        spots is about the same as the black background. The spot radii are in a        narrow range [0.10, 0.15]. Each tile of the texture contains 1270 spots.</p>      <pre>Scale(0.2, LotsOfSpots(0.5, 0.1, 0.15, 0.1))</pre>      <img src="images/20200405_LotsOfSpots_d1.png" alt="Scale(0.2, LotsOfSpots(0.5, 0.1, 0.15, 0.1))"        title="Scale(0.2, LotsOfSpots(0.5, 0.1, 0.15, 0.1))"        height="511"        width="511">      <p>Below, the density is 70%, spot radii range from 0.1 to 1.0, producing        a total of 170 spots.</p>      <pre>Scale(0.2, LotsOfSpots(0.7, 0.1, 1.0, 0.1))</pre>      <img src="images/20200405_LotsOfSpots_d2.png" alt="Scale(0.2, LotsOfSpots(0.7, 0.1, 1.0, 0.1))"        title="Scale(0.2, LotsOfSpots(0.7, 0.1, 1.0, 0.1))"        height="511"        width="511">      <p>Below, the density is 90% and the spot radii range from 0.1 to 1.0,        producing a total of 245 spots. First the code randomly distributes        enough spots to meet the given density level. Then it tries to adjust        the spot positions to avoid overlap. After 200 failed adjustment        attempts, it stops and gives up. That happened here, the spots were too        crowded for it to find a non-intersecting arrangement in 200 tries.        (They are “pretty well” distributed but some still overlap.) Letting it        run for 1000 tries only slightly improved the layout, so I decided the        time taken was not justified.</p>      <pre>Scale(0.2, LotsOfSpots(0.9, 0.1, 1.0, 0.1))</pre>      <img src="images/20200405_LotsOfSpots_d3.png" alt="Scale(0.2, LotsOfSpots(0.9, 0.1, 1.0, 0.1))"        title="Scale(0.2, LotsOfSpots(0.9, 0.1, 1.0, 0.1))"        height="511"        width="511">    </div>    <div class="post" id="20200403"> <a href="#20200403" class="date">April 3,        2020</a>      <h1>Experimental <em>LotsOfSpots</em></h1>      <p>This is a new, updated version of <em>LotsOfSpots</em>, loosely based        on the version from <a href="http://www.red3d.com/cwr/texsyn/diary.html#20100208"          class="date">February
          8, 2010</a>. As the original version aspired to be, this one is        defined everywhere on the texture plane. It achieves this by the boring        method of tiling a pattern of spots. The square tiling has a period of        10x10 and is centered at the origin. Since the typical <strong>TexSyn</strong>        “rendering interval” is [-1, +1] in both X and Y, normally the cyclic        nature of the spot pattern would normally be hidden “off screen” unless        the texture was scaled down significantly or subjected to a nonlinear        warp.</p>      <p>The first texture sample shows a typical portion of <em>LotsOfSpots</em>.        (This prototype is returning a grayscale image.) In this case the <code>density</code>        of spots is ~70%, the radii are distributed between 0.1 and 0.9 (with        smaller values preferred) and a soft transition zone width of 0.1. The        second texture sample shows the result of zooming out—scaling by 0.13—to        reveal the tile size. The non-center tiles are tinted blue.</p>      <pre><span class="comment">// Parameters are: density, min_radius, max_radius, softness</span><br>LotsOfSpots(0.7, 0.1, 0.9, 0.1)</pre>      <img src="images/20200403_LotsOfSpots.png" alt="" title="" height="511" width="511">      <pre>Scale(0.13, LotsOfSpots(0.7, 0.1, 0.9, 0.1))</pre>      <img src="images/20200403_LotsOfSpots_zoomed_out.png" alt="" title="" height="511"        width="511">      <p>One more random example, showing why it is important for textures to be        defined across the entire texture plane. Here is the previous texture        (including its blue tint outside the central tile) as seen through a <em>MobiusTransform</em>        operator. This happens to be the same Möbius transformation that was the        “third example” on the <a href="#20200128">January 28</a> example        below. Because a texture operator can arbitrarily scale, stretch, or        warp its input texture, it is impossible to anticipate what part of a        texture will be sampled.</p>      <pre>MobiusTransform(Vec2(-0.958788, 1.64993),                Vec2(-1.54534, -0.593485),                Vec2(1.29155, -0.931471),                Vec2(0.768266, 0.24665),                Translate(Vec2(-0.75, -0.75),                          Scale(0.13,                                LotsOfSpots(0.7, 0.1, 0.9, 0.1)))</pre>      <img src="images/20200403_LotsOfSpots_Mobized.png" alt="" title="" height="511"        width="511">    </div>    <div class="post" id="20200401"> <a href="#20200401" class="date">April 1,        2020</a>      <h1>Incremental Halton sequence</h1>      <p>As mentioned before, there was an earlier version of the <strong>TexSyn</strong>        library, begun in 2008. It included some experimental operators (<em>LotsOfSpots</em>        replaced by <em>SpotsInCircle</em>) for generating patterns of many        spots, see <a href="http://www.red3d.com/cwr/texsyn/diary.html#20100208"          class="date">February
          8, 2010</a> and <a href="http://www.red3d.com/cwr/texsyn/diary.html#20100209"          class="date">February
          9, 2010</a>. It is easy to curate a finite collection of spots, hence        the easier-to-implement <em>SpotsInCircle</em> operator. It would be        much more convenient to have a distribution defined throughout the        texture plane. This is the beauty of Perlin noise which is defined at        every point in the space.</p>      <p>I had a vague memory of a talk at SIGGRAPH by someone who worked on the        remarkable game <a href="https://en.wikipedia.org/wiki/Spore_%282008_video_game%29">Spore</a>,        describing the technique they used to distribute game objects, say trees        in a forest. A search led me to the website of <a href="http://www.andrewwillmott.com/">Andrew
          Willmott</a> and the <a href="http://www.andrewwillmott.com/s2007">materials
          from the SIGGRAPH 2007 session</a> including “Fast Object        Distribution” about his incremental Halton sequence. The materials        include sample code called <code>IncrementalHalton.cpp</code>. This is        the first 300 points generated by the sequence. Ignoring the Z        coordinate, I drew a circle centered on the Halton point. The first 100        are large orange, then medium green, then small purple. </p>      <p>I'm still learning about this. Generally the points seem “well        distributed” over the unit square. Also informally, new points “tend to        fall between” older points. As I understand it, the points are often        “spaced out” but there is no lower bound on the space between any two        points. So if you consider the points to be disks, there will        occasionally be collisions (overlaps). For more background information,        see this excellent “explorable explanation” by <a href="https://observablehq.com/@jrus">Jacob
          Rus</a> about the <a href="https://observablehq.com/@jrus/halton">Halton
          Sequence</a>. </p>      <p>The incremental Halton sequence was developed to allow its use in an        interactive game and its interactive editors for game worlds. While        performance matters in <strong>TexSyn</strong>, that is not its main        focus. I want to look at some other methods for constructing spot        patterns, including those that might do some pre-calculation (Such as,        for example, to adjust spacing between disks). </p>      <img src="images/20200401_Halton.png" alt="incremental Halton sequence test"        title="incremental Halton sequence test"        height="511"        width="511">    </div>    <div class="post" id="20200330"> <a href="#20200330" class="date">March 30,        2020</a>      <h1>RTFM and phew!</h1>      <p>A <code>Texture</code> instance now has an initially empty <code>cv::Mat</code>        to serve as a rasterization cache. Both <code>Texture::displayInWindow()</code>        and <code>Texture::writeToFile()</code> are refactored to first call <code>Texture::rasterizeToImageCache()</code>        to ensure a cached rendering is available before displaying it in a        window or writing it to a file. The cache means that (for a given <code>size</code>,        etc.) each Texture will be rendered at most one time.</p>      <p>After doing that, I happened to be browsing through the <strong>OpenCV</strong>        doc—as one does—and noticed <a href="https://docs.opencv.org/trunk/d3/d63/classcv_1_1Mat.html#a952ef1a85d70a510240cb645a90efc0d"><code>cv::Mat::forEach()</code></a>        which applies a given function to all image pixels using all available        parallelism. That is nearly identical to what I did yesterday in        lovingly hand crafted code. So: (a) remember to always RTFM, and (b) how        does the speed of using this <code>forEach()</code> tool compare with        the hand written code? </p>      <p>It turns out that my code is slightly faster (about 11%) but it would        have been significantly faster and easier to write the code using the <code>forEach()</code>        tool provided by <strong>OpenCV</strong>. I am curious about why my        code was faster, or said another way, if the <strong>OpenCV</strong>        code could be made faster.</p>    </div>    <div class="post" id="20200329"> <a href="#20200329" class="date">March 29,        2020</a>      <h1>Multi-threading for faster <em>Blur</em></h1>      <p><code>Texture::displayInWindow()</code> does pixel-by-pixel rendering        of textures for display. I refactored it to loop for each “row” from top        to bottom, kicking off a new <code>std::thread</code> to calculate the        pixels across the row. So for the images shown here, 511 threads get        created, then the operating system schedules them in parallel onto the        hardware CPU cores available. On my laptop (MacBook Pro (Mid 2014))        there are 8 cores. (Or I guess four hardware cores—each of which        supports two “hyperthreads”—so if feels like eight cores.) In any case,        my Instruments app shows utilization at nearly 8 cores: around 785.4%        CPU usage. To see those numbers, I had to really crank up the rendering        load. Shown below is a very smooth (almost no sampling noise) of the        standard <em>Blur</em> benchmark. As described on <a href="#20200317">March
          17</a>, I set <code>Blur::sqrt_of_subsample_count</code> to 60,        meaning each <code>Blur::getColor()</code> sample performed 3600        (60x60) subsamples.</p>      <p>Overall, <strong>the multi-threading version of Blur is about <u>five</u>          times faster</strong> than the previous version, which itself was        about twice as fast as the one before that.</p>      <img src="images/20200329_Blur_60x60_subsamples.png" alt="Blur 60x60 subsamples"        title="Blur 60x60 subsamples"        height="511"        width="511">      <p>We also do square textures!&nbsp; 😲 I expect to normally use        disk-shaped renderings. There was half-hearted support in the code for        rectangular images. In the ongoing refactoring of the rasterization        code, I made it a little more official. Here is the same texture shown        above, with 60x60 subsampling, and the new <code>disk</code> parameter        set to <code>false</code> to change the rasterization mode.</p>      <img src="images/20200329_Blur_60x60_square.png" alt="Blur 60x60 square" title="Blur 60x60 square"        height="511"        width="511">    </div>    <div class="post" id="20200326"> <a href="#20200326" class="date">March 26,        2020</a>      <h1>Experiments with <em>Shade</em></h1>      <p>Here are some more examples of the experimental <em>Shade</em>        operator. Three examples below show different bump maps combined with        this <em>ColorNoise</em>:</p>      <pre>color_noise = ColorNoise(0.6, Vec2(), 0.2)</pre>      <img src="images/20200326_color_noise.png" alt="color_noise" title="color_noise"        height="511"        width="511">      <p>Here the bump map is Brownian noise. The result looks a bit like shaded        mountainous terrain.</p>      <pre>brownian = Brownian(0.3, Vec2(9, -5), black, white)</pre>      <img src="images/20200326_Brownian.png" alt="brownian" title="brownian" height="511"        width="511">      <pre>Shader(Vec3(1, 3, 6), 0.3, color_noise, brownian)  <span class="comment">// parameters are: to_light, ambient_level, color_texture, bump_texture</span></pre>      <img src="images/20200326_Brownian_shaded.png" alt="Shader(Vec3(1, 3, 6), 0.3, color_noise, brownian)"        title="Shader(Vec3(1, 3, 6), 0.3, color_noise, brownian)"        height="511"        width="511">      <p>Here the bump map is basic Perlin noise. The result looks a bit like        sand dunes in late afternoon.</p>      <pre>noise = Noise(0.1, Vec2(9, -5), black, white)</pre>      <img src="images/20200326_Noise.png" alt="noise" title="noise" height="511"        width="511">      <pre>Shader(Vec3(1, 3, 6), 0.3, color_noise, noise)</pre>      <img src="images/20200326_Noise_shaded.png" alt="Shader(Vec3(1, 3, 6), 0.3, color_noise, noise)"        title="Shader(Vec3(1, 3, 6), 0.3, color_noise, noise)"        height="511"        width="511">      <p>Here the bump map is a soft-edged Spot with a flat spot in the center        and around the outside. The result looks a bit like wide-brimmed hat,        seen from above, in oblique light.</p>      <pre>spot = Spot(Vec2(), 0.3, white, 0.95, black)</pre>      <img src="images/20200326_Spot.png" alt="spot" title="spot" height="511" width="511">      <pre>Shader(Vec3(1, 3, 6), 0.3, color_noise, spot)</pre>      <img src="images/20200326_Spot_shaded.png" alt="Shader(Vec3(1, 3, 6), 0.3, color_noise, spot)"        title="Shader(Vec3(1, 3, 6), 0.3, color_noise, spot)"        height="511"        width="511">      <p>I am a bit surprised at how “shiny” these renders appear. This is a        purely diffuse reflection model with no specular highlights. <em>Shade</em>        applied to <em>Brownian</em> produces a very bumpy surface, but it        looks a bit like wrinkled aluminum. (I thought perhaps it was related to        RGB clipping when shading adds to ambient illumination. But I see it        even when ambient is zero.) Here is <em>Shade</em> applied to <em>Brownian</em>        (again) alongside a version smoothed with <em>Blur</em>:</p>      <pre>Shader(Vec3(1, 3, 6), 0.3, color_noise, brownian)<br>Shader(Vec3(1, 3, 6), 0.3, color_noise, Blur(0.1, brownian))</pre>      <img src="images/20200326_Brownian_shaded.png" alt="Shader(Vec3(1, 3, 6), 0.3, color_noise, brownian)"        title="Shader(Vec3(1, 3, 6), 0.3, color_noise, brownian)"        height="511"        width="511">      <img src="images/20200326_Brownian_filtered.png" alt="Shader(Vec3(1, 3, 6), 0.3, color_noise, brownian)"        title="Shader(Vec3(1, 3, 6), 0.3, color_noise, brownian)"        height="511"        width="511">    </div>    <div class="post" id="20200325"> <a href="#20200325" class="date">March 25,        2020</a>      <h1>That’s no moon...</h1>      <p>This <em>Shader</em> texture operator is just an experiment. I am not        sure if it belongs in the <strong>TexSyn</strong> library. It is        essentially a computer graphic “shader” that scales the brightness of a        <u>color texture</u> according to another interpreted as a <u>bump          texture</u>: a height field based on luminance. It scales the input        color by Lambertian reflectance, based on a given light direction and        the height field's surface normal. This is a test pattern whose height        field is a hemisphere, shaded with a <code>to_light</code> vector of <code>Vec3(-2,
          2, 4)</code>:</p>      <img src="images/20200325_no_moon.png" alt="That’s no moon..." title="That’s no moon..."        height="511"        width="511">      <pre>green_stripes = Grating(Vec2(), Color(0, 1, 0), Vec2(0, 0.1), Color(1,1,1), 0.2)hemisphere = ShadedSphereTest(Vec3(0, 0, 1))Shader(Vec3(-2, 2, 4), 0, green_stripes, hemisphere)</pre> <img src="images/20200325_green_stripes.png" alt="green_stripes" title="green_stripes"        height="511"        width="511">      <br>      <img src="images/20200325_hemisphere.png" alt="hemisphere" title="hemisphere"        height="511"        width="511">      <br>      <img src="images/20200325_sphere_stripes.png" alt="Shader(Vec3(-2, 2, 4), 0, green_stripes, hemisphere)"        title="Shader(Vec3(-2, 2, 4), 0, green_stripes, hemisphere)"        height="511"        width="511">      <p>I am not sure if it makes sense to put 3d shading in a 2d texture        synthesis library. I will give it more thought and try other        experiments.</p>    </div>    <div class="post" id="20200323"> <a href="#20200323" class="date">March 23,        2020</a>      <h1>Add “strength” parameter to <em>EdgeEnhance</em></h1>      <p>In the original <a href="#20200301">March 1</a> description of <em>EdgeDetect</em>        and <em>EdgeEnhance</em>, they were both shown as (like <em>Blur</em>)        having two parameters: a <code>float width</code> (the diameter of the        convolution kernel) and an input texture. In the <a href="http://www.red3d.com/cwr/texsyn/diary.html#20090824">previous
          version</a> of this library, <em>EdgeEnhance</em> had another        parameter, a <code>float strength</code> that controlled how <u>how          much</u> edge enhancement there was. At first I thought that parameter        might be unneeded, and now changed my mind. That is, <em>EdgeEnhance</em>        is now defined as:</p>      <pre>Add(input_texture, AdjustBrightness(strength, Subtract(input_texture, Blur(width, input_texture))))</pre>      <p>Shown below are six combinations of filter <code>width</code> (big=0.2        or small=0.1) and enhancement <code>strength</code> (low=0.66,        normal=1.0, high=1.33). Filter <code>width</code> controls how far        across the texture the edge enhancement extends, while <code>strength</code>        is its amplitude. At the end is the input texture <code>colors</code>        and the code that defines it. Note how “flat” the input texture looks        compared to the edge enhanced versions, how much more “pop” they have at        the edges.</p>      <pre>EdgeEnhance(0.2, 0.66, colors)  <span class="comment">// wide width and low strength.</span></pre>      <img src="images/20200323_EdgeEnhance_02_066.png" alt="EdgeEnhance(0.2, 0.66, colors)"        title="EdgeEnhance(0.2, 0.66, colors)"        height="511"        width="511">      <pre>EdgeEnhance(0.2, 1.00, colors)  <span class="comment">// </span><spanclass="comment">wide width and normal strength.</span></pre>      <img src="images/20200323_EdgeEnhance_02_100.png" alt="EdgeEnhance(0.2, 1.00, colors)"        title="EdgeEnhance(0.2, 1.00, colors)"        height="511"        width="511">      <pre>EdgeEnhance(0.2, 1.33, colors)  <span class="comment">// </span><spanclass="comment">wide width and high strength.</span></pre>      <img src="images/20200323_EdgeEnhance_02_133.png" alt="EdgeEnhance(0.2, 1.33, colors)"        title="EdgeEnhance(0.2, 1.33, colors)"        height="511"        width="511">      <pre>EdgeEnhance(0.1, 0.66, colors)  <span class="comment">// narrow</span><spanclass="comment"> width and low strength.</span></pre>      <img src="images/20200323_EdgeEnhance_01_066.png" alt="" title="" height="511"        width="511">      <pre>EdgeEnhance(0.1, 1.00, colors)  <span class="comment">// </span><spanclass="comment">narrow</span><spanclass="comment"> width and normal strength.</span></pre>      <img src="images/20200323_EdgeEnhance_01_100.png" alt="EdgeEnhance(0.1, 1.00, colors)"        title="EdgeEnhance(0.1, 1.00, colors)"        height="511"        width="511">      <pre>EdgeEnhance(0.1, 1.33, colors)  <span class="comment">// </span><spanclass="comment">narrow</span><spanclass="comment"> width and high strength.</span></pre>      <img src="images/20200323_EdgeEnhance_01_133.png" alt="EdgeEnhance(0.1, 1.33, colors)"        title="EdgeEnhance(0.1, 1.33, colors)"        height="511"        width="511">      <pre><span class="comment">// Definition of the "colors" texture used as input for the examples above.</span>b = Color(0, 0, 0)w = Color(1, 1, 1)colors = SoftMatte(SoftThreshold(0.60, 0.64,                                 Rotate(5, Noise(0.2, Vec2(-1, -4), b, w))),                   SoftMatte(SoftThreshold(0.60, 0.64,                                           Rotate(3, Noise(0.2, Vec2(+1, +3), b, w))),                             SoftMatte(SoftThreshold(0.60, 0.64,                                                     Rotate(1, Noise(0.2, Vec2(-2, +1), b, w))),                                       Uniform(0.5),                                       Uniform(Color(0.8, 0.8, 0))),                             Uniform(Color(0.8, 0, 0.8))),                   Uniform(Color(0, 0.8, 0.8)))</pre>      <img src="images/20200323_colors.png" alt="colors" title="colors" height="511"        width="511">      <p>[Update on March 24] One more example of the strength parameter: I        wanted to look at high values of <code>strength</code>. Here is a some        <em>Wrapulance ColorNoise</em> that has been reduced in saturation and        brightness, then operated on by <em>EdgeEnhance</em> with a strength of        5.</p>      <pre>grayish_color_noise = AdjustBrightness(0.7, AdjustSaturation(0.3, ColorNoise(0.5, Vec2(5,7), 0.8)))</pre>      <img src="images/20200324_grayish_color_noise.png" alt="grayish_color_noise"        title="grayish_color_noise"        height="511"        width="511">      <pre>EdgeEnhance(0.1, 5, grayish_color_noise)</pre>      <img src="images/20200324_EdgeEnhance_01_5.png" alt="EdgeEnhance(0.1, 5, grayish_color_noise)"        title="EdgeEnhance(0.1, 5, grayish_color_noise)"        height="511"        width="511">    </div>    <div class="post" id="20200321"> <a href="#20200321" class="date">March 21,        2020</a>      <h1><em>SliceShear</em></h1>      <p>I wrote the first version of <em>SliceShear</em> on January 25 but the        two tangents were interacting when they were supposed to be independent.        After several debugging failures I set it aside. Today I tried again and        found the right solution. This is yet another operator based on the idea        of a “slice” through texture space, a one dimensional texture. Here it        is used to laterally shift or shear another texture. (The scalar        luminance of the 1D texture is used as a relative translation.) The        parameters to <em>SliceShear</em> are: a tangent, center, and texture        to describe the “slice”, and a tangent, center to describe how the input        texture is sheared. Three examples which will hopefully make that more        clear are below. First, the <code>for_slice</code> texture from which        the shear-controlling slice will be taken and the <code>to_shear</code>        test pattern to which the <em>SliceShear</em> operator will be applied.</p>      <pre><span class="comment">// for_slice: noise in one direction, square wave in other direction.</span><br>white = Color(1, 1, 1)black = Color(0, 0, 0)gray = Color::gray(0.3)for_slice = Add(SliceGrating(Vec2(1, 0), Vec2(), Brownian(0.1, Vec2(), black, gray)),                Grating(Vec2(), black, Vec2(0, 0.1), gray, 0.2))</pre>      <img src="images/20200321_for_slice.png" alt="for_slice" title="for_slice"        height="511"        width="511">      <p>This <code>to_shear</code> is the input texture that will be shifted        by <em>SliceShear</em> according to a slice of <code>for_slice</code>.</p>      <pre>to_shear = Grating(Vec2(), Color(1, 0.5, 0), Vec2(0, 0.25), Color(0, 0.5, 1), 0.4)</pre> <img src="images/20200321_to_shear.png" alt="to_shear" title="to_shear"        height="511"        width="511">      <p>Here a <u>horizontal</u> slice (<code>Vec2(1, 0)</code>) through the        center of <code>for_slice</code> produces <u>noise</u> that controls <u>vertical</u>        shear (<code>Vec2(0, 1)</code>) of <code>to_shear</code>.</p>      <pre>SliceShear(Vec2(1, 0), Vec2(), for_slice, Vec2(0, 1), Vec2(), to_shear)</pre>      <img src="images/20200321_SliceShear_1.png" alt="SliceShear_1" title="SliceShear_1"        height="511"        width="511">      <p>Here a <u>vertical</u> slice (<code>Vec2(0, 1)</code>) through the        center of <code>for_slice</code> produces <u>square waves</u> that        controls <u>vertical shear</u> (<code>Vec2(0, 1)</code>) of <code>to_shear</code>.</p>      <pre>SliceShear(Vec2(0, 1), Vec2(), for_slice, Vec2(0, 1), Vec2(), to_shear)</pre>      <img src="images/20200321_SliceShear_2.png" alt="SliceShear_2" title="SliceShear_2"        height="511"        width="511">      <p>Here a <u>horizontal</u> slice (<code>Vec2(1, 0)</code>) through the        center of <code>for_slice</code> produces <u>noise</u> that controls <u>diagonal
          shear</u> (<code>Vec2(1, 1)</code>) of <code>to_shear</code>.</p>      <pre>SliceShear(Vec2(1, 0), Vec2(), for_slice, Vec2(1, 1), Vec2(), to_shear)</pre>      <img src="images/20200321_SliceShear_3.png" alt="SliceShear_3" title="SliceShear_3"        height="511"        width="511">    </div>    <div class="post" id="20200319"> <a href="#20200319" class="date">March 19,        2020</a>      <h1>Repeatable randomness</h1>      <p>Describing the first version of <em>Blur</em> on <a href="#20200225">February
          25</a> I said: “...this prototype stochastic filter is not        repeatable/deterministic. The noise pattern could be different on a        subsequent run...” Now that is fixed. I used the <code>Texture::diff()</code>        utility to compare two “identical” textures made with <em>Blur</em>:<br>      </p>      <pre>Texture::diff(Blur(0.2, Grating(Vec2(), yellow, Vec2(0.2, 0.2), blue, 0.01)),              Blur(0.2, Grating(Vec2(), yellow, Vec2(0.2, 0.2), blue, 0.01)))</pre>      <p>This <code>Texture::diff</code> comparison is from before today's        change. The magnitude of the errors resulting from non-repeatable random        number was actually very small. Here I have scaled up by a factor of 10        the brightness of of the third image, which is the <em>AbsDiff</em>        (absolute value of the difference) of the two input textures:</p>      <img src="images/20200319_Blur_diff_before.png" alt="" title="" height="334"        width="1000">      <p>This <code>Texture::diff</code> comparison is after today's change.        The third texture is exactly zero/black according to <code>Texture::diff</code>'s
        logging:</p>      <img src="images/20200319_Blur_diff_after.png" alt="" title="" height="334"        width="1000">      <p>When looking up a color at a position in texture space <code>Blur::getColor()</code>        now hashes the <code>Vec2</code> position to generate a “seed”, which        is used to initialize a local <code>RandomSequence</code> object, which        is used to jiggle the subsamples. So any two calls to <code>Blur::getColor()</code>        with an identical position (exact <code>Vec2</code> equality) will use        an identical set of subsamples. Hashing utilities for <code>float</code>        and <code>Vec2</code> were added yesterday. <code>RandomSequence</code>        was added today. Still working on integrating it with existing utilities        like <code>Vec2::randomUnitVector()</code>. </p>    </div>    <div class="post" id="20200317"> <a href="#20200317" class="date">March 17,        2020</a>      <h1>Blurry McBlurface</h1>      <p>After yesterday's entry, I reconsidered my life choices. The newer        hash-table-based-subsample-reusing version of <em>Blur</em> was about        twice as fast but had much more unappealing noise. Which is to say:        uglier and <u>only</u> twice as fast. That got me wondering. What if,        in the previous version of <em>Blur</em>, I just reduced the number of        subsamples per <code>getColor()</code>sample so it was twice as fast?        How would that compare, in terms of image quality, with the new version?        The previous version used a jiggled grid of 15x15 or 225 subsamples per        sample. (The current code assumes the grid is square.) Near one half of        that is an 11x11 grid with 121 subsamples, or a 10x10 grid with 100        subsamples. The first two textures below are (1) previous version of <em>Blur</em>        but with 11x11 or 121 subsamples, and (2) the new version of <em>Blur</em>        which randomly selects 1/4 of the subsamples of a 30x30 grid or 225        samples. The first one looks significantly better to me (smoother, less        noisy). These are both approximately twice as fast as the previous        version of <em>Blur</em> at 15x15 or 225 subsamples. All of the        textures below are made with <code>Blur(0.2, sample)</code>. </p>      <img src="images/20200317_Blur_old_yb_02_11x11.png" alt="121 (11x11) subsamples"        title="121 (11x11) subsamples"        height="511"        width="511">      <img src="images/20200316_Blur_newer_yb_02.png" alt="225 (30x30 / 4) subsamples"        title="225 (30x30 / 4) subsamples"        height="511"        width="511">      <p>For comparison, here is (1) the previous version of <em>Blur</em> with        15x15 or 225 subsamples, and (2) the previous version of <em>Blur</em>        with 10x10 or 100 subsamples. The latter begins to look too noisy to me,        so I lean toward 11x11 as the default setting.</p>      <img src="images/20200317_Blur_old_yb_02_15x15.png" alt="225 (15x15) subsamples"        title="225 (15x15) subsamples"        height="511"        width="511">      <img src="images/20200317_Blur_old_yb_02_10x10.png" alt="100 (10x10) subsamples"        title="100 (10x10) subsamples"        height="511"        width="511">      <p>As much as I like to use hash tables, I will move that new <code>Blur</code>        version to the code graveyard. The previous version will remain. I added        <code>Blur::sqrt_of_subsample_count</code> to allow setting the <em>n</em>        of the <em>n</em>² subsample grid. This global parameter allows        adjusting the speed/quality trade-off for a given application.</p>      <p>In any case, the <em>Blur</em> operator and the ones based on it (<em>EdgeDetect</em>        and <em>EdgeEnhance</em>) are by far the slowest ones in TexSyn.        Despite the “monkey wrenches” of doing convolution on procedurally        defined textures—there are bound to be ways to accelerate that        computation on a GPU. (Perhaps using <strong>OpenCV</strong> as the        implementation layer, as currently done for image display and image file        I/O.) Next time the slow performance of Blur causes trouble, it might be        time to bite that bullet.</p>    </div>    <div class="post" id="20200316"> <a href="#20200316" class="date">March 16,        2020</a>      <h1>Back to <em>Blur</em></h1>      <p>Over the last four days I have been evaluating different ways to        implement the <em>Blur</em> texture operator (see <a href="#20200226">February
          26</a>). This is very well-trod ground in signal/image processing and        computer graphics. Blurring (low pass filtering) is accomplished by <em>convolving</em>        a “bell shaped” <em>kernel</em> with the input image data. Analytically        the kernel is usually a rotationally symmetric <em>Gaussian</em>        distribution (<u>the</u> bell curve). Among other benefits, this makes        the 2d convolution <em>separable</em>, allowing it to be computed as        the product of two 1d convolutions (so O(<em>n</em>) rather than O(<em>n²</em>)).
        Modern graphics hardware (GPUs) allow lightning fast implementation of        convolution-based low pass filtering. It is so fast and easy that my        macOS display system uses blurring as a design element, giving some        parts of the GUI a real time “frosted glass” look.</p>      <p>The structure of <strong>TexSyn</strong> throws some monkey wrenches        into this approach. It is fine to apply convolution to an image, even a        large image, which is bounded, rectangular, and uniformly sampled.&nbsp;        But <strong>TexSyn</strong> textures have infinite (well, floating        point) range, so it is daunting to collect the infinite input image, let        alone to produce the infinite output. Also, most “interesting” blur        kernels span a narrow range (too small and the output looks        unchanged—too large and the result looks like a uniform color). But in        principle there is no natural bound on the size of a kernel. An infinite        texture convolved with an unbounded kernel is—well, a lot of        computation.</p>      <p>Of course we never need an infinite texture. We sample some portion of        it at some sampling frequency, then display it on the screen or write it        to an image file. But the <em>Blur</em> operator never knows what part        of the texture will be sampled, nor at what frequency, nor whether that        sampling is at a unifrom frequency across the image. (Consider a <em>MobiusTransform</em>        (<a href="#20200128">January 28</a>) or <em>Wrap</em> (<a href="#20200115">January
          15</a>) operator applied to the result of a <em>Blur</em> operator.        The <em>Blur</em> will receive some number of <code>getColor()</code>        sampling requests, but cannot know anything about their bounds,        distribution, or spacing.)</p>      <p>The approach taken previously (<a href="#20200226">February 26</a>) was        to implement each <code>getColor()</code> call with a point convolution        based on distributed sampling of the input under the kernel. An earlier        version used sample points uniformly distributed across the nonzero part        of the kernel. Then to reduce noise, it was changed to use a grid of        “cells” each of which was sampled by a point uniformly distributed        across the cell. At the time, I selected a 15x15 sampling grid spanning        the kernel. Note that this implies the cost per <code>getColor()</code>        call is constant (O(<em>1</em>)). It will always use 225 subsamples.        This means large kernels are the same speed as small ones, but the big        ones have more noise.</p>      <p>But the time to compute <em>Blur</em> seemed too long. I looked for        ways to accelerate it. For two <code>getcolor()</code> calls at nearby        locations—say within the diameter of the kernel, like “adjacent        pixels”—many of the subsample cells will overlap. I tried caching these,        and reusing them from one <code>getColor()</code> call to the next. But        then all the samples in the vicinity of a cell go the identical “random”        sample, which caused obvious artifacts on the scale of the cells. (I        tried both O(<em>log n</em>) <code>std::map</code> (red-black trees)        and O(<em>1</em>) <code>std::unordered_map</code> (hash tables). The        hash tables were noticeably faster.)</p>      <p>The last tweak was to cache just the one “random” sample per cell, but        to make the grid finer (twice as many subsamples in each direction, so 4        times more cells) then for each <code>getColor()</code> to select a        different random 1/4 set of cells. This is done by skipping whole        randomly-chosen rows and columns of grid. </p>      <p>The old version is clearly smoother and less noisy. It looks much        better. The new version is much noisier but runs more than twice as        fast. (New execution time is about 45% of old, for rendering a 511x511        texture.) At the moment I cannot choose one over the other. I guess I        will leave both versions in for now and make a global switch to choose        between them.</p>      <p>This <code>sample</code> is the input for the rest of the texture        samples:</p>      <pre>sample = Grating(Vec2(), yellow, Vec2(0.2, 0.2), blue, 0.01)</pre>      <img src="images/20200314_grating_yb.png" alt="sample" title="sample" height="511"        width="511">      <pre>Blur(0.2, sample)  // Previous version of Blur.</pre>      <img src="images/20200314_Blur_old_yb.png" alt="old Blur(0.2, sample)" title="old Blur(0.2, sample)"        height="511"        width="511">      <pre>Blur(0.2, sample)  // New faster, noisier version of Blur.</pre>      <img src="images/20200316_Blur_newer_yb_02.png" alt="new Blur(0.2, sample)"        title="new Blur(0.2, sample)"        height="511"        width="511">      <pre>Blur(0.5, sample)  // Previous version of Blur.</pre>      <img src="images/20200316_Blur_old_yb_05.png" alt="old Blur(0.5, sample)"        title="old Blur(0.5, sample)"        height="511"        width="511">      <pre>Blur(0.5, sample)  // New faster, noisier version of Blur.</pre>      <img src="images/20200316_Blur_newer_yb_05.png" alt="new Blur(0.5, sample)"        title="new Blur(0.5, sample)"        height="511"        width="511">      <pre>EdgeDetect(0.2, sample)  // Previous version of Blur.</pre>      <img src="images/20200316_EdgeD_old_yb_02.png" alt="old EdgeDetect(0.2, sample)"        title="old EdgeDetect(0.2, sample)"        height="511"        width="511">      <pre>EdgeDetect(0.2, sample)  // New faster, noisier version of Blur.</pre>      <img src="images/20200316_EdgeD_newer_yb_02.png" alt="new EdgeDetect(0.2, sample)"        title="new EdgeDetect(0.2, sample)"        height="511"        width="511">    </div>    <div class="post" id="20200312"> <a href="#20200312" class="date">March 12,        2020</a>      <h1><em>Row</em></h1>      <p>The <em>Row</em> operator tiles the texture plane by copying and        translating a portion (a fixed width “stripe”) of an input texture. Its        parameters are two <code>Vec2</code> values: <code>basis</code> and <code>center</code>.        The <code>basis</code> vector spans from one boundary of a “stripe” to        the other (the length of <code>basis</code> is the width of the stripe,        and its orientation is normal to the stripe's “axis”). The center        position adjust the “phase” of stripes, effectively sliding the input        texture relative to the stripe. The stripe that is centered on <code>center</code>        is a “fixed point” of the <em>Row</em> transform, it remains identical        to the input texture. All these examples use the same <code>spots_and_bg</code>        textures used in <a href="#20200311">yesterday's</a> post about <em>Ring</em>.        In each case, the <code>center</code> is at the origin, at the middle        of these texture samples, and between the two spots.</p>      <pre>Row(Vec2(0.4, 0), Vec2(), spots_and_bg)</pre>      <img src="images/20200312_row_1.png" alt="Row(Vec2(0.4, 0), Vec2(), spots_and_bg)"        title="Row(Vec2(0.4, 0), Vec2(), spots_and_bg)"        height="511"        width="511">      <pre>Row(Vec2(0.35, 0.35), Vec2(), spots_and_bg)</pre>      <img src="images/20200312_row_2.png" alt="Row(Vec2(0.35, 0.35), Vec2(), spots_and_bg)"        title="Row(Vec2(0.35, 0.35), Vec2(), spots_and_bg)"        height="511"        width="511">      <pre>Row(Vec2(0, 0.6),  Vec2(), spots_and_bg)</pre>      <img src="images/20200312_row_3.png" alt="Row(Vec2(0, 0.6),  Vec2(), spots_and_bg)"        title="Row(Vec2(0, 0.6),  Vec2(), spots_and_bg)"        height="511"        width="511">      <p>An array can be formed with two nested <code>Row</code> operations.        But note this only works “correctly” when the two <code>basis</code>        vectors are perpendicular. Admittedly, my definition of “correct” is at        best idiosyncratic: that all cells of the array be identical (and        correspond to the neighborhood of <code>center</code> on the input        texture). In the previous version of this library I provided an Array        operator which worked “correctly” for oblique arrays with non-orthogonal        bases (see <a href="http://www.red3d.com/cwr/texsyn/diary.html#20090426">here</a>).
        With the benefit of hindsight, I think <strong>TexSyn</strong> does not        need an Array operator.</p>      <pre>Row(Vec2(0.17, 0.52), Vec2(), Row(Vec2(-0.52, 0.17), Vec2(), spots_and_bg))</pre>      <img src="images/20200312_row_4.png" alt="Row(Vec2(0.17, 0.52), Vec2(), Row(Vec2(-0.52, 0.17), Vec2(), spots_and_bg))"        title="Row(Vec2(0.17, 0.52), Vec2(), Row(Vec2(-0.52, 0.17), Vec2(), spots_and_bg))"        height="511"        width="511">    </div>    <div class="post" id="20200311"> <a href="#20200311" class="date">March 11,        2020</a>      <h1><em>Ring</em></h1>      <p>The <em>Ring</em> operator takes a pie-slice-shaped sector from an        input texture, copying and rotating around a center to create the whole        “pie.” The parameters to <em>Ring</em> are: <code>float copies</code>—how
        many “pie pieces” there are, <code>Vec2 basis</code>—the direction of        the bisector of the sector to be copied, <code>Vec2 center</code>—around
        which the sectors are rotated, and the input texture. The ray from <code>center</code>,        along the direction of <code>basis</code>, is a “fixed point” of the <em>Ring</em>        operator: texture within the fixed sector is identical to the input        texture. The three textures shown below are: </p>      <ul>        <li>the input texture (called <code>spots_and_bg</code> below)</li>        <li>the result of applying <em>Ring</em> with 10 <code>copies</code>,          vertical <code>basis</code>, and <code>center</code> near the bottom</li>        <li>the result of applying <em>Ring</em> with 5 <code>copies</code>,          the <code>basis</code> along the diagonal up and to the right, and          the <code>center</code> in the lower left.</li>      </ul>      <p>Note that the “shadow” in the input texture is directly below the        bright spot. In the second example, where the center of rotation is        below the spots, the “shadows” in each sector point toward the center.        In the third example, the shadows point in a “clockwise” orientation.        The <code>copies</code> parameter is given as a floating point value,        but is interpreted as a positive integer greater than zero (via <code>round</code>,        <code>abs</code>, and <code>max</code>).</p>      <img src="images/20200311_spots_and_bg.png" alt="spots_and_bg" title="spots_and_bg"        height="511"        width="511">      <pre>Ring(10.1, Vec2(0, 1), Vec2(0, -0.9), spots_and_bg)</pre>      <img src="images/20200311_Ring_1.png" alt="Ring(10.1, Vec2(0, 1), Vec2(0, -0.9), spots_and_bg)"        title="Ring(10.1, Vec2(0, 1), Vec2(0, -0.9), spots_and_bg)"        height="511"        width="511">      <pre>Ring(-4.8, Vec2(1, 1), Vec2(1, 1) * -0.35, spots_and_bg)</pre>      <img src="images/20200311_Ring_2.png" alt="Ring(-4.8, Vec2(1, 1), Vec2(1, 1) * -0.35, spots_and_bg)"        title="Ring(-4.8, Vec2(1, 1), Vec2(1, 1) * -0.35, spots_and_bg)"        height="511"        width="511">      <p>Definition for <code>spots_and_bg</code> used above:</p>      <pre><span class="comment">// Color noise reduced in brightness and saturation.</span>bg = AdjustBrightness(0.7,                      AdjustSaturation(0.1,                                       ColorNoise(0.5, Vec2(-1, -3),  0.6)))<span class="comment">// Matte an 80% gray spot over a "shadow", then that over the background.</span>spots_and_bg = SoftMatte(Translate(Vec2(0, 0.1), spot),                         SoftMatte(spot, bg, AdjustBrightness(0.8, bg)),                         Uniform(Color::gray(0.8)))</pre>    </div>    <div class="post" id="20200310"> <a href="#20200310" class="date">March 10,        2020</a>      <h1>Lambda combinations — wait, what?!</h1>      <p>Oh, sorry, it looks like another digression into arcane c++, but this        time from the perspective of Lisp and the lambda calculus. (As described        in the 1941 book <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=yWCYDwAAQBAJ&amp;oi=fnd&amp;pg=PA1&amp;dq=%22calculi+of+lambda+conversion%22#v=onepage&amp;q=%22calculi%20of%20lambda%20conversion%22&amp;f=false">The
          Calculi of Lambda-Conversion</a> by Alonzo Church, a contemporary and        collaborator of Alan Turing.) I first programmed in Lisp around 1972        when I was an undergraduate. I loved it and it has stuck with me for the        rest of my life. The “lambda functions” introduced into c++ in 2011        appear to be based on the same concept in the Lisp programing language        (since 1959) which is in turn based on the same concept in the lambda        calculus (since 1941). You can see they are very similar:</p>      <pre><span class="comment">;; A Lisp lambda expression, a function of two arguments, returning them as a pair:</span>(lambda (x y) (cons x y))<span class="comment">;; To apply it to parameters, we form a “lambda combination”, a list of three;; objects: the function and a value for each of the two parameters:</span>((lambda (x y) (cons x y)) 1 2)</pre>      <pre><span class="comment">// A c++ lambda function of two arguments, returning them as a pair:</span>[](int x, int y){return std::make_pair(x, y);}<span class="comment">// To apply it to parameters, we write the function followed by an argument list:</span>[](int x, int y){return std::make_pair(x, y);}(1, 2);</pre>      <p>The key thing here is that during the execution of the lambda function,        the parameters values (<code>1</code> and <code>2</code>) are <strong>bound</strong>        to the parameter names (<code>x</code> and <code>y</code>). On <a href="#20200305">March
          5</a> I talked about how the “lifetime” of temporary c++ objects was        inconveniently short. Defining a nested procedural texture caused the        not-top-level operators to be automatically deleted at the end of the        assignment statement. (Worth noting in this context that the lifetime of        Lisp objects is “as long as you need them.” It uses garbage collection        to know when you are really done with them.) I implemented a solution,        using copying, but it felt too clumsy. In the end I wrote a utility to        take the nested texture tree as a parameter, then perform the needed        tasks, before returning and allowing the temporary object to be deleted.</p>      <p>What I realized today is that “lambda binding” can be used to fix this        issue in c++ the same way lambdas and macros are used in Lisp to form        new language extensions (e.g. <em>let</em> used to bind local        variables). See below a “lambda combination” in c++. It corresponds to        the code used to create the three sample textures for the <a href="#20200309">March
          9</a> entry about <em>Mirror</em>. Within the curly brackets <code>{}</code>        are three calls to a display utility. (The three were described        yesterday as “...the original input, the result of mirroring it about        the Y axis, and the result of mirroring about the Y axis then the X        axis...”) Above that is the function's parameter name list: a <em>Texture</em>        reference named <code>test</code>. After the the curly brackets is the        parameter value list that the function is applied to: a nested <em>Texture</em>        tree of seven operators, generators, and some primitives like numbers, <em>Vec2</em>s,
        and <em>Color</em>s. While this is definitely a “weird” c++ style, it        is limited to the places where it is used (sample code to support this        document) rather than being inside the definition of all operators.</p>      <pre><span class="comment">// Lexical capture spec ("all, by reference")</span>.[&amp;]<span class="comment">// Parameter type and name list (here a Texture reference named "test").</span>(const Texture&amp; test)<span class="comment">// Body of lambda where parameter values are bound to parameter names.// Texture tree is bound to "test" for lifetime of this block.</span>{    Texture::displayAndFile(test);    Texture::displayAndFile(Mirror(Vec2(0, 1), Vec2(), test));    Texture::displayAndFile(Mirror(Vec2(1, 0),                                   Vec2(),                                   Mirror(Vec2(0, 1), Vec2(), test)));}<span class="comment">// Parameter value list, a nested tree of various Texture objects.</span>(Subtract(Uniform(Color(1, 1, 1)),          Multiply(ColorNoise(0.5, Vec2(-1, -3), 0.6),                   Colorize(Vec2(1, 0),                            Vec2(),                            Multiply(grating, grating),                            Brownian(0.3, Vec2(-1, -3),                                     Color(1, 1, 1),                                     Color(0, 0, 0))))));</pre>    </div>    <div class="post" id="20200309"> <a href="#20200309" class="date">March 9,        2020</a>      <h1><em>Mirror</em></h1>      <p><em>Mirror</em> across an arbitrary line in texture space. The line is        defined by a tangent and center point. Shown below three textures: the        original input, the result of mirroring it about the Y axis, and the        result of mirroring about the Y axis then the X axis.</p>      <img src="images/20200309_test.png" alt="test" title="test" height="511" width="511">      <pre>Mirror(Vec2(0, 1), Vec2(), test)</pre>      <img src="images/20200309_Mirror_y.png" alt="Mirror y" title="Mirror y" height="511"        width="511">      <pre>Mirror(Vec2(1, 0), Vec2(), Mirror(Vec2(0, 1), Vec2(), test))</pre>      <img src="images/20200309_Mirror_y_then_x.png" alt="Mirror y then x" title="Mirror y then x"        height="511"        width="511">      <p>Just a side note about the <code>test</code> pattern above. I was        wrapping presents and one of the gift wrapping papers had a pattern with        curvy lines. I was thinking about how to do that in <strong>TexSyn</strong>.        Here is an experiment in that direction, a <code>squiggles</code>        texure:</p>      <pre>// Vertical black and white sine wave grating.grating = Grating(Vec2(0.1, 0), Color(1, 1, 1), Vec2(0.3, 0), Color(0, 0, 0), 1)// Sharpen brightness peaks by squaring.grating_squared = Multiply(grating, grating)// Brownian noise also in shades of gray.noise = Brownian(0.3, Vec2(-1, -3), Color(1, 1, 1), Color(0, 0, 0))// Colorize the noise with sharpened sine wave to get the squiggles texture below.<b>squiggles</b> = Colorize(Vec2(1, 0), Vec2(), grating_squared, noise)<br><br>// The test pattern above was: squiggles times color-noise subtracted from white:<br><strong>test</strong> = Subtract(Uniform(Color(1, 1, 1)),                Multiply(ColorNoise(0.5, Vec2(-1, -3), 0.6),                         squiggles))</pre>      <img src="images/20200309_squiggles.png" alt="squiggles" title="squiggles"        height="511"        width="511">    </div>    <div class="post" id="20200308"> <a href="#20200308" class="date">March 8,        2020</a>      <h1><em>BrightnessWrap</em></h1>      <p><em>BrightnessWrap</em>, analogous to <em>SoftThreshold</em>, takes        two brightness thresholds and an input texture. The brightness of the        input texture is “wrapped around” in the sense of modulus (fmod) the        brightness interval between the two thresholds. Then that brightness        interval is adjusted to cover the interval between black and white. (The        adjustment to full range had not been done in the previous version of        this library. I now think it makes more sense. But I need to think about        it some more.) These operations on brightness happen in        hue-saturation-value color space, so only brightness (value) is changed.        The hue and saturation remain unchanged.</p>      <pre>gray_noise = Brownian(0.3, Vec2(-1, -3), white, black)<br>BrightnessWrap(0.4, 0.6, gray_noise)</pre>      <img src="images/20200308_gray_noise.png" alt="gray noise" title="gray noise"        height="511"        width="511">      <img src="images/20200308_gray_BrightnessWrap.png" alt="BrightnessWrap(0.4, 0.6, gray_noise)"        title="BrightnessWrap(0.4, 0.6, gray_noise)"        height="511"        width="511">      <pre>color_noise = ColorNoise(0.5, Vec2(-1, -3), 0.6)<br>BrightnessWrap(0.4, 0.6, color_noise)</pre>      <img src="images/20200308_color_noise.png" alt="color noise" title="color noise"        height="511"        width="511">      <img src="images/20200308_color_BrightnessWrap.png" alt="BrightnessWrap(0.4, 0.6, color_noise)"        title="BrightnessWrap(0.4, 0.6, color_noise)"        height="511"        width="511">    </div>    <div class="post" id="20200306"> <a href="#20200306" class="date">March 6,        2020</a>      <h1><em>Twist</em></h1>      <p><em>Twist</em> an input texture around a given <code>center</code>.        The twist has infinite extent but falls off as 1/r. This creates a        spiral tightly curved near <code>center</code> and asymptotically        approaching zero curvature for increasing radius. The <em>Twist</em> is        parameterized by an <code>angle_scale</code> (bigger values mean more        twisting) and a <code>radius_scale</code> which adjusts the rate of        falloff (bigger values pull the twisting closer to <code>center</code>).
        For a given radius from center, the twist angle is: <code>angle =          angle_scale / ((radius * radius_scale) + 1)</code></p>      <pre>// radial pattern:center = Vec2(0.9, 0);radial = SliceToRadial(Vec2(0, 0.318),                       center,                       Grating(Vec2(0, -0.1), Color(0.3, 0.15, 0),                               Vec2(0, +0.1), Color(0.9, 0.9, 0),                               0.3));</pre>      <img src="images/20200306_radial.png" alt="radial" title="radial" height="511"        width="511"><br>      <pre>Twist(1, 1, center, radial)</pre>      <img src="images/20200306_Twist_1_1.png" alt="Twist(1,1,...)" title="Twist(1,1,...)"        height="511"        width="511"><br>      <p>With a larger <code>radius_scale</code> the twisting is pushed toward        the center. So further out, the radial features are nearly straight.</p>      <pre>Twist(1, 9, center, radial)</pre>      <img src="images/20200306_Twist_1_9.png" alt="Twist(1,9,...)" title="Twist(1,9,...)"        height="511"        width="511"><br>      <p>Stronger <code>radius_scale</code> causes more twisting.</p>      <pre>Twist(7, 1, center, radial)</pre>      <img src="images/20200306_Twist_7_1.png" alt="Twist(7,1,...)" title="Twist(7,1,...)"        height="511"        width="511"><br>      <p>Stronger <code>radius_scale</code> and more concentration near center.</p>      <pre>Twist(7, 9, center, radial)</pre>      <img src="images/20200306_Twist_7_9.png" alt="Twist(7,9,...)" title="Twist(7,9,...)"        height="511"        width="511"><br>      <p>An interesting mistake. Here the <em>Twist</em> is applied to the same        point near the right side, but the radial pattern was located at the        center.</p>      <img src="images/20200306_near_miss.png" alt="near miss" title="near miss"        height="511"        width="511"><br>    </div>    <div class="post" id="20200305"> <a href="#20200305" class="date">March 5,        2020</a>      <h1>Infrastructure / c++ temporaries</h1>      <p>No new texture synthesis results today. Just boring code stuff. If you        do not care about arcane c++ this is not worth reading.</p>      <p>I went on a bit of a wild goose chase. While testing <strong>TexSyn</strong>,        and creating the sample textures for this document, I'd been bothered by        an issue related to the “lifetime” of temporary values in c++        expressions. This led me deep into the c++ rabbit hole, stackoverflow,        and the “<a href="https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern">curiously
          recurring template pattern</a>” (which reminds me of what we called        “mixins” in the Flavors OOPS in Lisp (specifically: Lisp Machine Lisp)        back in the 1980s). I managed to “fix” the issue I was digging into,        then decided the solution seemed too intrusive/heavyweight, and not        worth keeping. I will describe it here, save the code in the graveyard,        and move on. This was the example I was testing with—furry blue and        green stripes—which I think of as being written like this, three nested        constructors of <strong>TexSyn</strong> classes: </p>      <pre>Multiply(Grating(Vec2(-0.1, -0.1), greenish, Vec2(0.1, 0.1), bluish, 0.5),         Furbulence(0.2, Vec2(3, 4), gray10, white))</pre>      <img src="images/20200305_fuzzy_blue_green_stripes.png" alt="furry blue and green stripes"        title="furry blue and green stripes"        height="511"        width="511">      <p>This is defined as the product of two generators: <em>Multiply</em>        applied to a <em>Grating</em> and a <em>Furbulence</em>:</p>      <img src="images/20200305_grating.png" alt="blue and green stripes" title="blue and green stripes"        height="511"        width="511">      <img src="images/20200305_furbulence.png" alt="furriness" title="furriness"        height="511"        width="511">      <p>The problem I kept running into is that I want to create these        procedural textures by writing a nested expressions (as in the code        block above), bind them to a variable in my program, then invoke “member        functions” of the <em>Texture</em> class on them to: display on the        screen, write to an image file, and occasionally other things.        Specifically, if I write:</p>      <pre>Multiply test(Grating(Vec2(-0.1, -0.1), greenish, Vec2(0.1, 0.1), bluish, 0.5),              Furbulence(0.2, Vec2(3, 4), gray10, white);</pre>      <p>It creates a <em>Multiply</em> instance named <code>test</code> which        contains references to two other <em>Texture</em> instances. (Generally        these procedural textures are “trees” with operations as branching nodes        and generators as leaves.) However, written like this, c++ considers        those calls to the constructors of <em>Grating</em> and <em>Furbulence        </em>to be&nbsp; “temporaries.” By the time the execution reaches the        semicolon at end of that expression, it assumes we are done with        them—that their “lifetime” has expired—so it deletes them (freeing their        resources, including the memory they occupy). When we get around to        using the composed <em>Texture</em> tree, only the named, root node        remains. And it now has dangling references to nonexistent objects.        Trying to then render the texture to the screen results in a visit to        the debugger. I had been working around this by making each operator a        named top level object, avoiding any use of nested (unnamed, temporary)        subobjects:</p>      <pre>Grating grating(Vec2(-0.1, -0.1), greenish, Vec2(0.1, 0.1), bluish, 0.5);Furbulence furbulence(0.2, Vec2(3, 4), gray10, white);Multiply multiply(grating, furbulence);</pre>      <p>This does not capture the composition of nested objects used in TexSyn.        It seemed I wanted to extend the lifetime of nested <em>Texture</em>        objects. I found various approaches to this but none seemed right. I        decided that perhaps the most straightforward approach would be to <b>copy</b>        the <em>Texture</em> parameters passed into my operators, so preserving        their lifetime as long as I needed them. Copying them did not seem        burdensome since these procedural textures are very small, typically        less than 100 bytes, just to store the parameters. But copying was        complicated by the fact that all these operators and generators are        subclasses of <em>Texture</em> and are passed as “polymorphic”        references (essentially pointers) of type <code>Texture&amp;</code>. So        for example, it was trivial to copy the <em>Grating</em> object passed        into <em>Multiply</em>, but all <em>Multiply</em> knew was that it had        been given a generic <em>Texture</em>, not that it was a <em>Grating</em>.        Naturally, I am not the first programmer who found a need to copy class        instances given only a pointer to the base class. This stackoverflow        post—<a href="https://stackoverflow.com/questions/5731217/how-to-copy-create-derived-class-instance-from-a-pointer-to-a-polymorphic-base-c/">How
          to copy/create derived class instance from a pointer to a polymorphic          base class?</a>—was right on point, and had a <a href="https://stackoverflow.com/questions/5731217/how-to-copy-create-derived-class-instance-from-a-pointer-to-a-polymorphic-base-c/5731259#5731259">good
          answer</a> by “ltjax” It was based on that “curiously recurring        template pattern” mentioned above. I followed the recipe in that answer        (modifying <em>Texture</em>, <em>Multiply</em>, <em>Grating</em>, and        <em>Furbulence</em>) and presto, it worked! <strong>Yay!</strong> But        it would mean rewriting the inheritance spec and the constructor of        every <strong>TexSyn</strong> operator. And the benefit was probably        limited to “hand written” texture code. To be sure everything I have        done over the last couple of months has been in that category. But the        intended eventual use of this library for GP-based texture optimization        would probably not benefit.</p>      <p>In the end, I backed up, thought about the specific problem I had and        found a lightweight solution with a small code footprint. Rather than        try to extend the “lifetime” of temporaries outside a given c++        statement I just moved everything I needed to do inside that statement.        I refactored some utility functions of <em>Texture</em>. Now I can pass        in an arbitrarily nested expression of <strong>TexSyn</strong> element        constructors. Then, during its lifetime, the texture is rendered to the        screen, and optionally encoded into a image file. That is much less        trouble, though perhaps not quite as elegant, as where I was at midday        when I was at “peak geek.” Sometime you just need to step back from the        precipice.</p>      <p>(The API change was to add <code>Texture::displayAndFile()</code> and        <code>Texture::waitKey()</code>. They were built from refactored bits of        <code>Texture::displayInWindow()</code> and <code>Texture::writeToFile()</code>.)</p>    </div>    <div class="post" id="20200304"> <a href="#20200304" class="date">March 4,        2020</a>      <h1><em>AdjustBrightness</em></h1>      <p>The <em>AdjustBrightness</em> operator multiplies all colors of a        texture by a given scale factor. Here we see a <em>ColorNoise</em>        texture (as on <a href="#20200303">March 3</a>) in the center and the        result of adjusting it by factors of 0.5 and 2. </p>      <p>The scaling happens in RGB space. Note that for screen display, and for        writing to image files, colors are clipped to the faces of the unit RGB        color cube. So some of the colors will have been scaled up outside the        unit cube and then been clipped back in, leading to brightness        artifacts. See also <em>Multiply</em> which forms the product of two        textures. In the previous version of this library there was a <em>Tint</em>        operator which multiplied a <em>Texture</em> by a <em>Color</em>.</p>      <pre>cn = ColorNoise(1, Vec2(2, 3), 0.8)AdjustBrightness(0.5, cn)AdjustBrightness(2.0, cn)</pre>      <img src="images/20200304_AdjustBrightness_down.png" alt="AdjustBrightness(0.5, cn)"        title="AdjustBrightness(0.5, cn)"        height="511"        width="511">      <br>      <img src="images/20200303_ColorNoise.png" alt="original cn" title="original cn"        height="511"        width="511">      <br>      <img src="images/20200304_AdjustBrightness_up.png" alt="AdjustBrightness(2.0, cn)"        title="AdjustBrightness(2.0, cn)"        height="511"        width="511">    </div>    <div class="post" id="20200303"> <a href="#20200303" class="date">March 3,        2020</a>      <h1><em>AdjustSaturation</em></h1>      <p>Operating in HSV (hue, saturation, value) color space, the <em>AdjustSaturation</em>        operator applies a scale factor to saturation, then clips it back into        the range [0, 1]. The textures below show a sample of <em>Wrapulance          ColorNoise</em> (second texture) and the result of applying <em>AdjustSaturation</em>        with a factor of 0.3 and 3.0:</p>      <pre>cn = ColorNoise(1, Vec2(2, 3), 0.8)AdjustSaturation(0.3, cn)AdjustSaturation(3.0, cn)</pre>      <img src="images/20200303_AdjustSaturation_down.png" alt="AdjustSaturation(0.3, cn)"        title="AdjustSaturation(0.3, cn)"        height="511"        width="511">      <br>      <img src="images/20200303_ColorNoise.png" alt="original cn" title="original cn"        height="511"        width="511">      <br>      <img src="images/20200303_AdjustSaturation_up.png" alt="AdjustSaturation(3.0, cn)"        title="AdjustSaturation(3.0, cn)"        height="511"        width="511">    </div>    <div class="post" id="20200302"> <a href="#20200302" class="date">March 2,        2020</a>      <h1><em>AdjustHue</em></h1>      <p>Operating in HSV (hue, saturation, value) color space, the <em>AdjustHue</em>        operator rotates hue by a given <code>offset</code>. In <strong>TexSyn</strong>,        hue is defined on the interval [0, 1]. So hue and <code>offset</code>        are added and the fractional part of the sum (“f-modulo”) becomes the        new hue. In this example, <em>BrightnessToHue</em> assigns a “rainbow”        pattern to a warped gray gradient. Then <em>AdjustHue</em> rotates the        pattern halfway around (180° of phase).</p>      <pre>grad = Gradation(Vec2(0, -1), Color(1, 1, 1), Vec2(0, 1), Color())warp = MobiusTransform(Vec2(0.24665, 1.44486),                       Vec2(-0.184825, 1.64791),                       Vec2(0.391668, -1.24418),                       Vec2(1.04597, -0.412046),                       grad)color1 = BrightnessToHue(0.7, warp)color2 = AdjustHue(0.5, color1)</pre>      <img src="images/20200302_color1.png" alt="color1" title="color1" height="511"        width="511">      <img src="images/20200302_color2.png" alt="color2" title="color2" height="511"        width="511">    </div>    <div class="post" id="20200301"> <a href="#20200301" class="date">March 1,        2020</a>      <h1><em>EdgeDetect</em> and <em>EdgeEnhance</em></h1>      <p><em>Blur</em> is a low pass filter that removes high frequencies.        Conversely, <em>EdgeDetect</em> is a high pass filter that removes low        frequencies. <em>EdgeDetect</em> is built on top of <em>Blur</em>        using the concept of <a href="https://en.wikipedia.org/wiki/Unsharp_masking">unsharp
          masking</a> — a texture is blurred then, subtracting the blurred        version from the original leaves the high frequency edge texture. Adding        the edges back to the original gives <em>EdgeEnhance</em> which        emphasizes the edges of the original texture. Here is “<code>grays</code>”,
        a thresholded noise pattern of dark and light grays, the result of        applying <em>EdgeDetect</em> and the result of applying <em>EdgeEnhance</em>:</p>      <pre>EdgeDetect(0.2, grays)<br>EdgeEnhance(0.2, grays)</pre>      <img src="images/20200301_grays.png" alt="grays" title="grays" height="511"        width="511">      <br>      <img src="images/20200301_grays_edge_detect.png" alt="grays edge detect" title="grays edge detect"        height="511"        width="511">      <br>      <img src="images/20200301_grays_edge_enhance.png" alt="grays edge enhance"        title="grays edge enhance"        height="511"        width="511">      <p>Similarly, here is a thresholded noise pattern of three colors, the        result of applying <em>EdgeDetect</em> and the result of applying <em>EdgeEnhance</em>:</p>      <pre>EdgeDetect(0.2, colors)<br>EdgeEnhance(0.2, colors)</pre>      <img src="images/20200301_colors.png" alt="colors" title="colors" height="511"        width="511">      <br>      <img src="images/20200301_color_edge_detect.png" alt="color edge detect" title="color edge detect"        height="511"        width="511">      <br>      <img src="images/20200301_color_edge_enhance.png" alt="color edge enhance"        title="color edge enhance"        height="511"        width="511">    </div>    <div class="post" id="20200228"> <a href="#20200228" class="date">February        28, 2020</a>      <h1><em>SoftThreshold</em></h1>      <p>The <em>SoftThreshold</em> operator remaps an interval of brightness        to “full range.” The operator's parameters are two intensity level        (generally between 0 and 1) and an input texture. As in the 2009        version, for a gray scale texture, this means that any part of the input        darker than the lower brightness bound is mapped to black, and any part        brighter than the upper brightness bound is mapped to white. Parts of        the input that fall between the two bounds are remapped to range between        black and white. In this example, parts of the gray <em>Noise</em>        texture below brightness 0.2 become black, above 0.7 become white. “Mach        bands” can be seen around the bright parts of the image that have been        clipped to white (and less obviously in the blacks):</p>      <pre>grays = Noise(0.4, Vec2(), Color(0, 0, 0), Color(1, 1, 1));threshold_grays = SoftThreshold(0.2, 0.7, grays);</pre>      <img src="images/20200228_grays.png" alt="grays" title="grays" height="511"        width="511">      <img src="images/20200228_threshold_grays.png" alt="threshold grays" title="threshold grays"        height="511"        width="511">      <p>In addition, this version of <em>SoftThreshold</em> handles colored        input textures in an analogous fashion. (The earlier version always        returned a gray scale result.) The input texture is converted to        hue-saturation-value color space, the value(/brightness/intensity) is        remapped and clipped (as described above) while the hue and saturation        components remain unchanged. Here a <em>ColorNoise</em> is thresholded        by its intensity. For example, note that near the center of the        thresholded texture, there is a clipped patch of yellow and pink. These        colors are as bright as they can be (in unit RGB space) while their hue        and saturation vary as before.</p>      <pre>colors = ColorNoise(0.6, Vec2(), 0)threshold_colors = SoftThreshold(0.4, 0.75, colors)</pre>      <img src="images/20200228_colors.png" alt="colors" title="colors" height="511"        width="511">      <img src="images/20200228_threshold_colors.png" alt="threshold colors" title="threshold colors"        height="511"        width="511">      <p>This was the original motivation for <em>SoftThreshold</em>, dividing        a noise texture into black and white regions, like the pattern printed        on the cover of “old school” <a href="https://www.google.com/search?q=composition+books&amp;tbm=isch">composition
          books</a>.</p>      <pre>SoftThreshold(0.5, 0.55, Brownian(0.08, Vec2(), Color(0, 0, 0), Color(1, 1, 1)))</pre>      <img src="images/20200228_composition_book_cover.png" alt="composition book cover"        title="composition book coverx"        height="511"        width="511">      <p>Something analogous from a color noise.</p>      <pre>SoftThreshold(0.55, 0.6, ColorNoise cbc(0.15, Vec2(), 0))</pre>      <img src="images/20200228_color_book_cover.png" alt="color book cover" title="color book coverx"        height="511"        width="511">    </div>    <div class="post" id="20200227"> <a href="#20200227" class="date">February        27, 2020</a>      <h1><em>Colorize</em></h1>      <p><em>Colorize</em> is another “slice” based operator. A bit like <em>          BrightnessToHue</em> (see <a href="#20200113">January 13, 2020</a>)        it assigns colors to an input texture based on        brightness/intensity/luminance. But the sequence of colors comes from a        “slice” of another input texture. The parameters to <em>Colorize</em>        are: a <em>Vec2</em> <code>slice_tangent</code> and <code>center</code>        which define a “ray” in texture space, then a <code>texture_for_slice</code>        from which the colors are read, and a <code>texture_to_color</code>        whose luminance is mapped to colors along the ray on <code>texture_for_slice</code>.        (In fact, the “ray” is actually a line, since in <strong>TexSyn</strong>        color RGBs are bounded only by floating point range.) Here is a typical        call to <em>Colorize</em> and the resulting texture:</p>      <pre>Colorize(Vec2(0, 1), Vec2(), texture_for_slice, texture_to_color)</pre>      <img src="images/20200227_colorized.png" alt="" title="" height="511" width="511">      <p>Here are the two input textures, <code>texture_for_slice</code> is a <em>ColorNoise</em>        which supplies the sequence of colors (from the origin, up along the        vertical axis):</p>      <pre>texture_for_slice = ColorNoise(0.1, Vec2(2, 2), 0.6)</pre>      <img src="images/20200227_for_slice.png" alt="" title="" height="511" width="511">      <p>The <code>texture_to_color</code> parameter is a black and white <em>          Brownian</em> texture supplying the luminance which is mapped to the        ray of colors. The <code>texture_to_color</code> texture need not be        monochrome, but only its luminance matters to <em>Colorize</em>.</p>      <pre>texture_to_color = Brownian(0.4, Vec2(), Color(0, 0, 0), Color(1, 1, 1))</pre>      <img src="images/20200227_to_color.png" alt="" title="" height="511" width="511">    </div>    <div class="post" id="20200226"> <a href="#20200226" class="date">February        26, 2020</a>      <h1><em>Blur</em> with a “jiggled grid” of subsamples</h1>      <p>To reduce the noise from stochastic sampling in <em>Blur</em>, I tried        to reduce the variance between adjacent output samples. One way to do        this is to regularize the “random” subsamples. One common approach is to        construct a grid over the kernel, and take one subsample randomized        inside each square grid cell. This keeps the sampling density more        uniform (for example you don't just happen to get all samples be on the        left side of the kernel) while retaining the sampling's stochastic        nature.</p>      <p> That part seems to work. It looks like the noise now has less        magnitude. Unfortunately it is hard to tell for sure because something        else is definitely different between before and after.The new grid-based        version seems to have lower contrast than yesterday's        random-position-on-kernel version. Worse I don't immediately see what        causes this difference. Given that the kernel size is the width of a        black and a white stripe, the lower contrast seems more plausible. Here        is the improved(?) version with a 15x15 grid of subsamples:</p>      <img src="images/20200226_vs_blur_15x15.png" alt="15x15 grid of subsamples"        title="15x15 grid of subsamples"        height="511"        width="511">      <p>While here is yesterday's version with 225 subsamples randomly        distributed on the non-zero “support” of the circular kernel, which has        more contrast (brighter “whites” and darker “blacks” than today's        version): </p>      <img src="images/20200226_vs_blur_225_ss.png" alt="225 random subsamples"        title="225 random subsamples"        height="511"        width="511">      <p>The new version is about 20% faster since some of the gridded        subsamples fall outside the kernel and so are just skipped.</p>      <p><span style="color:white;">February 27, 2020</span> — An addendum: I'm        still puzzled by the difference in contrast of the two texture samples        above. I repeated the first sample (“jiggled grid” of subsamples) using        a kernel width of 0.1 instead of 0.2. Recall that each black or white        stripe has a width of 0.1. So I expect blurring with a 0.1 kernel to        produce full white along the center-line of (e.g.) the white strips        (since the entire kernel is then within the white stripe) and a soft        black↔︎white transition between the center-lines. That is indeed what I        see here, which makes me somewhat more confident that the new        jiggled-grid code is doing the right thing:</p>      <img src="images/20200227_blur_0.1_15x15.png" alt="0.1 kernel width, 15x15 subsamples"        title="0.1 kernel width, 15x15 subsamples"        height="511"        width="511">    </div>    <div class="post" id="20200225"> <a href="#20200225" class="date">February        25, 2020</a>      <h1>Experiments with <em>Blur</em></h1>      <p>I would like to include a <em>Blur</em> operator in the <strong>TexSyn</strong>        library to provide low pass filtering. (This would also provide a path        to high pass filtering—for edge detection and edge enhancement—via <a href="https://en.wikipedia.org/wiki/Unsharp_masking">unsharp
          masking</a>.) But there are some problems to solve. One is that these        are fundamentally kernel-based convolution operators, and so require        significantly more computation than other point-based operators. This        gets worse as the size of the convolution kernel increases. (Under        evolutionary selection, how should we limit that size in a principled        way? If evolution determines that a bigger and bigger kernel improves        fitness, who are we to argue?) Beyond that, while modern computers have        GPUs which can significantly accelerate traditional image processing        operations, these do not directly apply to the procedural textures used        in <strong>TexSyn</strong>. Textures here are resolution-agnostic, and        are not stored as 2d arrays of color values.</p>      <p>One possible approach to this stochastic sampling. An early example of        this in graphics was the “distributed sampling” of rays in <a href="https://renderman.pixar.com/">RenderMan</a>.        So rather than trying to define a rectangular array of “pixels” to feed        to a traditional image processing discrete convolution operation, we can        randomly sample points inside the kernel, look those up in an input        texture, and compute a weighted sum according to the convolution kernel.        This trades off computation for noise. Here is a pair of sharp gratings        composited with <em>SoftMatte</em>:</p>      <pre>spot = Spot(Vec2(), 0.6, white, 0.7, black)grating1 = Grating(Vec2(), white, Vec2(0.2, 0), black, 0.01)grating2 = Grating(Vec2(), white, Vec2(0, 0.2), black, 0.01)no_blur = SoftMatte(spot, grating1, grating2)</pre>      <img src="images/20200225_no_blur.png" alt="no_blur" title="no_blur" height="511"        width="511">      <p>Now the experimental stochastic <em>Blur</em> is applied to the inner        horizontal grating. Here the width of the LPF kernel is 0.2 (note: each        pair of black and white stripes has a width of 0.2) and 50 subsamples of        the input texture are used for each output sample, producing this very        noisy blurred texture:</p>      <pre>vs_blur = SoftMatte(spot, grating1, Blur(0.2, grating2))</pre>      <img src="images/20200225_vs_blur_50_ss.png" alt="vs_blur 50 subsamples" title="vs_blur 50 subsamples"        height="511"        width="511">      <p>Here 1000 subsamples are used per output sample. Even at this high        sampling rate, the blurred image has noticeable noise:</p>      <img src="images/20200225_vs_blur_1000_ss.png" alt="vs_blur 1000 subsamples"        title="vs_blur 1000 subsamples"        height="511"        width="511">      <p>Note that in addition to the other issues discussed above, this        prototype stochastic filter is not repeatable/deterministic. The noise        pattern could be different on a subsequent run. In the future, if this        stochastic approach is used, the pseudo-random generator should be        “re-seeded” for each output sample, perhaps by hashing the <em>Vec2</em>        texture coordinates of the sample. Also the number of subsamples used        should probably depend on the area of the circular kernel.</p>    </div>    <div class="post" id="20200223"> <a href="#20200223" class="date">February        23, 2020</a>      <h1>Rigid geometric transforms: <em>Scale</em>, <em>Rotate</em>, and <em>Translate</em></h1>      <p>Generally <strong>TexSyn</strong> includes rigid transformations in        the specification of its generators and operators to help automatic        program generation by GP (see <a href="#20191219">December 19, 2019</a>).
        Primarily for hand-written code I wanted to include operators for simple        rigid transformation. Each takes an input texture and either a scale        factor, rotation angle or translation <em>Vec2</em>. See some examples,        including simple order-dependent composition below. If these were to be        made available to GP, <em>Scale</em> and <em>Rotate</em> probably        should include <code>center</code> parameters.</p>      <pre>two_spots = Add(Spot(Vec2(+0.2, 0), 0.38, Color(0.7, 0, 0), 0.4, Color()),                Spot(Vec2(-0.2, 0), 0.38, Color(0, 0, 0.7), 0.4, Color()))</pre>      <img src="images/20200223_two_spots.png" alt="two_spots" title="two_spots"        height="511"        width="511">      <pre>scaled_spots = Scale(1.5, two_spots)</pre>      <img src="images/20200223_scaled_spots.png" alt="scaled_spots" title="scaled_spots"        height="511"        width="511">      <pre>scale_then_rotate = Rotate(pi / 4, scaled_spots)</pre>      <img src="images/20200223_scale_then_rotate.png" alt="scale_then_rotate" title="scale_then_rotate"        height="511"        width="511">      <pre>scale_rotate_translate = Translate(Vec2(0, 0.3), scale_then_rotate)</pre>      <img src="images/20200223_scale_rotate_translate.png" alt="scale_rotate_translate"        title="scale_rotate_translate"        height="511"        width="511">    </div>    <div class="post" id="20200128"> <a href="#20200128" class="date">January        28, 2020</a>      <h1><em>MobiusTransform</em></h1>      <p>I was recently reminded of this very nice “explorable explanation” of        the <a href="http://timhutton.github.io/mobius-transforms/">Möbius          transformation</a> of the complex number plane, by Tim Hutton in 2016.        Substituting the texture plane for the complex plane, and with some        math-hand-holding by Robert Bridson to invert the transformation        (thanks!), I prototyped this <em>MobiusTransform</em> texture operator.        Its parameters are four points on the plane and an input texture. In        these examples the input is the <code>plaid</code> texture as defined        in the entry for <a href="#20200115">January 15, 2020</a>. Using        Hutton's interactive tool I defined the four points for the first        example, which is just “off” an identity transform. That is, the        perpendicular diagonal stripes of <code>plaid</code> have been rotated        and slightly curved by the Möbius transformation. The next two (whose        “control points” were randomly generated <em>Vec2</em> values within 4        units of the origin) show increasing amounts of warp. The fourth example        (also randomly generated) shows an area of significant contraction of        the input texture. The current texture operators use point sampling so        areas of strong contraction inevitably produce aliasing “confetti” due        to undersampling (violating <a href="https://en.wikipedia.org/wiki/Nyquist_frequency">Nyquist's
          criteria</a>). Eventually <strong>TexSyn</strong> may be extended to        detect these contractions and supersample them. Or perhaps it will just        depend upon genetic programming to “vote down” textures with these        artifacts.</p>      <pre>// first example:MobiusTransform(Vec2(1,2), Vec2(0,.1), Vec2(.1,0), Vec2(1,-2), plaid)// third example:MobiusTransform(Vec2(-0.958788, 1.64993), Vec2(-1.54534, -0.593485), Vec2(1.29155, -0.931471), Vec2(0.768266, 0.24665), plaid)</pre>      <img src="images/20200128_MobiusTransform_0.png" alt="MobiusTransform 1" title="MobiusTransform 1"        height="511"        width="511">      <img src="images/20200128_MobiusTransform_5.png" alt="MobiusTransform 2" title="MobiusTransform 2"        height="511"        width="511">      <img src="images/20200128_MobiusTransform_1.png" alt="MobiusTransform 3" title="MobiusTransform 3"        height="511"        width="511">      <img src="images/20200128_MobiusTransform_2.png" alt="MobiusTransform 4" title="MobiusTransform 4"        height="511"        width="511">    </div>    <div class="post" id="yyyymmdd"> <a href="#yyyymmdd" class="date">January        24, 2020</a>      <h1><em>SliceToRadial</em></h1>      <p><em>SliceToRadial</em> maps a “slice” of its input texture—specified by        a <code>tangent</code> vector and <code>center</code> point—to rays        emanating from the <code>center</code> point. The three examples below        use the same color noise texture defined in the <a href="#20200123">January
          23</a> entry. This operator introduces a discontinuity along the <code>-tangent</code>        direction. In the first two examples that can be seen diagonally from        the center to the lower left, and in the third example from the center        to the left.</p>      <pre>SliceToRadial(Vec2(1, 1), Vec2(0, 0), cn);SliceToRadial(Vec2(1, 1), Vec2(0.5, 0.5), cn);SliceToRadial(Vec2(1, 0), Vec2(0.5, 0.5), cn);</pre> <img src="images/20200124_SliceToRadial1.png" alt="SliceToRadial 1" title="SliceToRadial 1"        height="511"        width="511">      <img src="images/20200124_SliceToRadial2.png" alt="SliceToRadial 2" title="SliceToRadial 2"        height="511"        width="511">      <img src="images/20200124_SliceToRadial3.png" alt="SliceToRadial 3" title="SliceToRadial 3"        height="511"        width="511">    </div>    <div class="post" id="20200123"> <a href="#20200123" class="date">January        23, 2020</a>      <h1>Texture “slices” and <em>SliceGrating</em></h1>      <p>As in an earlier version of this library, the term “slice” of a texture        refers to the pattern of colors along a line in texture space. This        could also be called a “1d texture” or a “transit.” Several operators in        this library take a texture as an input, then ignore all but one slice        of it. The slice is normally specified by a tangent vector and a point.        The magnitude of the tangent serves as a parameter of the operator.</p>      <p>So for example, <em>SliceGrating</em> takes a slice and “sweeps” it        perpendicular to the tangent. The slice is specified by two <em>Vec2</em>        parameters: <code>slice_tangent</code> and <code>center</code>. The        length of <code>slice_tangent</code> becomes a scale factor along the        slice, relative to the <code>center</code>. Here we see the input        texture, then three <em>SliceGrating</em>s made from it, each with a        different scale. In all three examples, the <code>center</code> of the        transform is in the upper right at (0.5, 0.5).</p>      <pre>cn = ColorNoise(0.6, Vec2(5, -2), 0.6);SliceGrating(Vec2(1, 2) * 2.0, Vec2(0.5, 0.5), cn);SliceGrating(Vec2(1, 2) * 1.0, Vec2(0.5, 0.5), cn);SliceGrating(Vec2(1, 2) * 0.5, Vec2(0.5, 0.5), cn);</pre> <img src="images/20200123_color_noise.png" alt="color_noise" title="color_noise"        height="511"        width="511">      <img src="images/20200123_SliceGrating1.png" alt="sg1" title="sg1" height="511"        width="511">      <img src="images/20200123_SliceGrating2.png" alt="sg2" title="sg2" height="511"        width="511">      <img src="images/20200123_SliceGrating3.png" alt="sg3" title="sg3" height="511"        width="511">    </div>    <div class="post" id="20200121"> <a href="#20200121" class="date">January        21, 2020</a>      <h1><em>Stretch</em></h1>      <p>This <em>Stretch</em> operator scales its input texture along a given        direction by a given factor (“anisotropic scaling”). Two        before-and-after examples are shown below. </p>      <p>First, a texture called <code>color_noise</code>, and the result of        stretching it by a factor of 0.2 at a 45° angle, with the transformation        centered at the origin. If you trace along the diameter from lower left        to upper right you might be able to see the same color pattern.</p>      <pre>Stretch(Vec2(0.2, 0).rotate(pi / 4), Vec2(0, 0), color_noise)</pre>      <img src="images/20200121_ColorNoise.png" alt="ColorNoise" title="ColorNoise"        height="511"        width="511">      <img src="images/20200121_Stretch_1.png" alt="Stretch 1" title="Stretch 1"        height="511"        width="511">      <br>      <br>      <p>Second, a texture called <code>three_spots</code>, and the result of        stretching it by a factor of 2, with the transformation centered at the        cyan spot's center (called <code>p2</code>) along the direction from        there to the origin. As a result, the original cyan spot and the        stretched cyan ellipse share the same center. The center of the yellow        and magenta spots have been displaced by the stretch.</p>      <pre>Stretch((-p2).normalize() * 2, p2, three_spots)</pre>      <img src="images/20200121_three_spots.png" alt="three_spots" title="three_spots"        height="511"        width="511">      <img src="images/20200121_Stretch_2.png" alt="Stretch 2" title="Stretch 2"        height="511"        width="511">    </div>    <div class="post" id="20200120"> <a href="#20200120" class="date">January        20, 2020</a>      <h1><em>ColorNoise</em></h1>      <p>Like <em>MultiNoise</em>, the <em>ColorNoise</em> generator takes        parameters <code>float scale</code>, <code>Vec2 center</code>, and a        float “<code>which</code>” to select among the types of noise        generators. It creates three “analogous” but uncorrelated noise textures        which are used as the red, green, and blue color components. The three <em>ColorNoise</em>        examples below are a low frequency basic Perlin <em>Noise</em>, a <em>Wrapulence</em>        at twice that frequency, and a higher frequency (12.5⨉) <em>Furbulence</em>.</p>      <pre>ColorNoise(1, Vec2(-7, 4), 0);ColorNoise(0.5, Vec2(-18, -20), 0.8);ColorNoise(0.08, Vec2(15, -12), 0.6);</pre>      <img src="images/20200120_ColorNoise_1.png" alt="ColorNoise 1" title="ColorNoise 1"        height="511"        width="511">      <br>      <img src="images/20200120_ColorNoise_2.png" alt="ColorNoise 2" title="ColorNoise 2"        height="511"        width="511">      <br>      <img src="images/20200120_ColorNoise_3.png" alt="ColorNoise 3" title="ColorNoise 3"        height="511"        width="511">    </div>    <div class="post" id="20200119"> <a href="#20200119" class="date">January        19, 2020</a>      <h1>Texture diff tool</h1>      <p>I made a debugging tool—<code>Texture::diff()</code>—that does a “diff”        of two textures, prints some numerical metrics, then displays the two        inputs and diff textures for visual comparison. The tool uses a new        texture operator called <em>AbsDiff</em> that simply takes the absolute        value (norm) of the difference between corresponding points on the two        input textures. This “abs of diff” is applied to the three RGB        components independently. This is a test of the diff utility on two        completely different textures:</p>      <pre>n = Noise(0.2, Vec2(), Color(1, 0, 0), Color(1, 1, 0));g = Grating(Vec2(), Color(0, 1, 1), Vec2(0.1, 0.1), Color(0, 0, 1), 0.5);Texture::diff(n, g);</pre>      <img src="images/20200119_Texture_diff.png" alt="Texture::diff()" title="Texture::diff()"        height="350"        width="1000">      <br>      <br>      <p>I used this diff tool to test a change to <code>Texture::rasterizeDisk()</code>        and while trying to come up with a closed form inverse mapping for        contraction in <em>StretchSpot</em>. A black third panel would indicate        the new code was equivalent to the old code. These colored fringes        indicate a mismatch:</p>      <img src="images/20200119_StretchSpot_diff.png" alt="Texture::diff()" title="Texture::diff()"        height="349"        width="1000">    </div>    <div class="post" id="20200116"> <a href="#20200116" class="date">January        16, 2020</a>      <h1><em>StretchSpot</em></h1>      <p><em>StretchSpot</em> makes a “fish eye” bulge of enlargement within a        given circular area of an input texture. Or, if the scale factor is less        than 1, makes a zone of contraction within the circular area. The code        below corresponds to the first image. The second is the same except for        the signs on the <code>dist</code> values specifying the centers of        stretch. Each is a series of four applications of <em>StretchSpot</em>        applied sequentially, two enlarging and two contracting. The input        texture is the same <code>plaid</code> example used below in the <a href="#20200115">January
          15</a> entry.</p>      <pre>radius = 0.8dist = 0.65StretchSpot(4.0,            radius,            Vec2(+dist, -dist),            StretchSpot(0.2,                        radius,                        Vec2(-dist, -dist),                        StretchSpot(0.2,                                    radius,                                    Vec2(-dist, +dist),                                    StretchSpot(4.0,                                                radius,                                                Vec2(+dist, +dist),                                                plaid))))</pre>      <img src="images/20200116_StretchSpot_1.png" alt="StretchSpot 1" title="StretchSpot 1"        height="511"        width="511">      <img src="images/20200116_StretchSpot_2.png" alt="StretchSpot 2" title="StretchSpot 2"        height="511"        width="511">    </div>    <div class="post" id="20200115"> <a href="#20200115" class="date">January        15, 2020</a>      <h1><em>Wrap</em></h1>      <p>Texture operator <em>Wrap</em> takes a half-plane of its input texture        and wraps it radially around a given point. The wrapping is defined by        three parameters: a float <code>width</code> that determines how much        of the half plane is used in the wrap, the <em>Vec2d</em> <code>center</code>        point of the wrap, and a <em>Vec2d</em> <code>fixed_ray</code> from        the center that will remain unchanged by the wrap. A “strip” of the half        plane (<code>width/2</code> on both sides of <code>fixed_ray</code>) is        transformed radially around <code>center</code>. (That is, a series of        rays parallel to <code>fixed_ray</code>, and displaced perpendicular to        it, become radial rays emanating from the <code>center</code> point.        This is related to a rectangular-(Cartesian)-to-polar transform.) <em>Wrap</em>        leads to a discontinuity in the direction of <code>-fixed_ray</code>        where the two edges of the “strip” become adjacent in the resulting        wrapped texture.</p>      <p>In the example below we see a test pattern called “plaid” and its image        under two applications of the <em>Wrap</em> operator. In <code>wrap1</code>,        the center is at the origin and <code>fixed_ray</code> points straight        up. In <code>wrap2</code>, the center is at (0.2, 0.2) and <code>fixed_ray</code>        points along the main diagonal (1, 1). There is a discontinuity in <code>wrap2</code>        along (-1, -1) while <code>wrap1</code> just happens to match up and        appear continuous. In both cases aliasing from point sampling is        apparent near the center of wrap.</p>      <pre>plaid = Add(Grating(Vec2(0, 0), Color(1, 0, 0),                    Vec2(0.1, 0.1), Color(0.3, 0, 0), 0.3),            Grating(Vec2(0, 0), Color(0, 1, 0),                    Vec2(-0.1, 0.1), Color(0, 0.3, 0), 0.3))                    wrap1 = Wrap(5, Vec2(0, 0), Vec2(0, 1), plaid)wrap2 = Wrap(5, Vec2(0.2, 0.2), Vec2(1, 1), plaid)</pre>      <img src="images/20200115_plaid.png" alt="“plaid” texture" title="“plaid” texture"        height="511"        width="511">      <br>      <img src="images/20200115_Wrap_1.png" alt="Wrap 1" title="Wrap 1" height="511"        width="511">      <img src="images/20200115_Wrap_2.png" alt="Wrap 2" title="Wrap 2" height="511"        width="511">    </div>    <div class="post" id="20200113"> <a href="#20200113" class="date">January        13, 2020</a>      <h1><em>BrightnessToHue</em></h1>      <p>The <em>BrightnessToHue</em> operator takes a texture and a hue_phase.        It maps luminance values on [0, 1] to hue. Luminance values 0 and 1 both        map to hue_phase and pass through all other hues in between. Here we        define a gray scale pattern called “gray_gratings” and colorize it with        <em>BrightnessToHue</em>. We see two version, with hue_phase of 0.0 and        0.5, which are 180° out of phase. So for example, those 8 spots        horizontally across the middle are red in one and cyan (“anti-red”) in        the other.</p>      <pre>gray_gratings = Add(Grating(Vec2(), black, Vec2(0, 2), gray50, 1),                    Add(Grating(-basis1, black, basis1, gray25, 1),                        Grating(-basis2, black, basis2, gray25, 1)))                        BrightnessToHue(0.0, gray_gratings)BrightnessToHue(0.5, gray_gratings)</pre>      <img src="images/20200113_gray_gratings.png" alt="gray_gratings" title="gray_gratings"        height="511"        width="511">      <br>      <img src="images/20200113_BrightnessToHue.png" alt="BrightnessToHue, hue_phase=0"        title="BrightnessToHue, hue_phase=0"        height="511"        width="511">      <img src="images/20200113_BrightnessToHue_2.png" alt="BrightnessToHue, hue_phase=0.5"        title="BrightnessToHue, hue_phase=0.5"        height="511"        width="511">    </div>    <div class="post" id="20200112"> <a href="#20200112" class="date">January        12, 2020</a>      <h1>GP considerations and <em>MultiNoise</em></h1>      <p>Thinking ahead to use with genetic programming, I added an alternate        version of the noise textures. <em>MultiNoise</em> has the same        parameters as the other noise texture generators, plus one additional        number between 0 and 1 which selects between the five noise generators.        This serves two purposes. (I think, although it remains to be seen.)        First, this selection parameter is subject to “jiggle” mutation,        allowing the type of noise (e.g. <em>Turbulence</em> versus <em>Furbulence</em>)        to vary under the control of evolutionary selection pressure. In        addition, I was concerned about letting noise textures “dominate” the        function set by having two many variations. This effects the choices        made during GP's initial construction of random programs, which in turn        influences the rest of the run. On the other hand, it may make more        sense to explicitly control this by giving each GP function a        “likelihood of being chosen for random program construction” parameter.        If so, that value could be set lower for the five varieties of noise        generators. The program for this demo texture is perhaps a little too        fiddly, but roughly: </p>      <pre>noise = MultiNoise(scale, center, black, magenta, 0.0);brownian = MultiNoise(scale, center, black, red, 0.2);turbulence = MultiNoise(scale, center, black, yellow, 0.4);furbulence = MultiNoise(scale, center, black, green, 0.6);wrapulence = MultiNoise(scale, center, black, cyan, 0.8);auto spot = [&amp;](float r){return Spot(center, r, black, r+0.05, white);};SoftMatte(spot(0.2),          wrapulence,          SoftMatte(spot(0.4),                    furbulence,                    SoftMatte(spot(0.6),                              turbulence,                              SoftMatte(spot(0.8),                                        brownian,                                        noise))))</pre>      <img src="images/20200112_MultiNoise.png" alt="MultiNoise texture generator"        title="MultiNoise texture generator"        height="511"        width="511">    </div>    <div class="post" id="20200111"> <a href="#20200111" class="date">January        11, 2020</a>      <h1>“<em>Wrapulence</em>”</h1>      <p><em>Wrapulence</em> is my name for yet another variation on <em>Turbulence</em>.        Here, each octave of the basic noise signal is scaled up in brightness        then “wrapped” down into the range [0, 1] using something like an <code>floor()</code>        or <code>fmod()</code>. The result is that the sharp stepwise changes        in intensity, wrapping from bright to dark, happen “at all scales.” (Or        at least at several scales. Recall that these multi-octave, 1/f fractal        noise generators use 10 levels of recursion.)</p>      <pre>Wrapulence(0.9, Vec2(-2, -9), Color(0, 0, 0), Color(1, 0.6, 0))</pre>      <img src="images/20200111_Wrapulence.png" alt="Wrapulence noise texture generator"        title="Wrapulence noise texture generator"        height="511"        width="511">    </div>    <div class="post" id="20200110"> <a href="#20200110" class="date">January        10, 2020</a>      <h1>“<em>Furbulence</em>”</h1>      <p><em>Furbulence</em> is my name for a variation on <em>Turbulence</em>.        Like <em>Brownian</em>, each are 1/f fractal noise. Perlin's <em>Turbulence</em>        introduces sharp features at the bottom (dark) end of the noise signal,        using an absolute value to fold the negative parts of the signal up into        the positive range. Similarly, <em>Furbulence</em> uses <u>two</u>        absolute values, one to fold the dark end up, and one to fold the bright        end down (with the scaling and shifting needed to make that work). The        result is that there are sharp discontinuities at the dark <u>and</u>        bright ends of the <em>Furbulence</em> signal. In this example there        are sharp hair-like features in the bright and dark regions of the        texture, here colored reddish blue and bluish red.</p>      <pre>Furbulence(0.25, Vec2(-1, 2), Color(1, .1, .3), Color(.3, .1, 1))</pre>      <img src="images/20200110_Furbulence.png" alt="Furbulence noise texture generator"        title="Furbulence noise texture generator"        height="511"        width="511">      <p>Just a comparison of <em>Furbulence</em> and <em>Turbulence</em>. The        inner <em>Furbulence</em> can be seen to have sharp features in both        white and yellow. The outer <em>Turbulence</em> has soft cloud-like        patches of blue broken by sharp black cracks.</p>      <pre>SoftMatte(Spot(Vec2(0, 0),               0.1, Color(0, 0, 0),               0.9, Color(1, 1, 1)),          Furbulence(0.1, Vec2(1, 2),                     Color(1, 1, 1), Color(.7, .7, 0)),          Turbulence(0.2, Vec2(-5, 7),                     Color(0, 0, 0), Color(.3, .3, 1)))</pre>      <img src="images/20200110_comparison.png" alt="Furbulence/Turbulence comparison"        title="Furbulence/Turbulence comparison"        height="511"        width="511">    </div>    <div class="post" id="20200106"> <a href="#20200106" class="date">January        6, 2020</a>      <h1>Turbulence</h1>      <p><em>Turbulence</em> is a variation on noise presented in Ken Perlin's        groundbreaking original SIGGRAPH 1985 paper: <a href="http://www.heathershrewsbury.com/dreu2010/wp-content/uploads/2010/07/AnImageSynthesizer.pdf">An
          Image Synthesizer</a>. Like <em>Brownian</em> noise, <em>Turbulence</em>        is composed of multiple octaves. At each level, the negative-going part        of the basic noise signal is “folded up” with an absolute value        operator. This produces soft/rounded features in the bright part of the        texture and sharp/discontinuous features in the dark parts of the        texture. In the example below, the sharp “valleys” are colored in dark        magenta, while the soft cloud-like highlights are colored orange.</p>      <pre>Turbulence(0.3, Vec2(2, -5), Color(0.3, 0, 0.3), Color(1, 0.6, 0))</pre>      <img src="images/20200106_Turbulence.png" alt="Turbulence noise texture generator"        title="Turbulence noise texture generator"        height="511"        width="511">    </div>    <div class="post" id="20200104"><a href="#20200104" class="date">January 4,        2020</a>      <h1><em>Brownian </em>— fractal 1/f Perlin noise</h1>      <p>This is 10 layers (octaves) of Perlin noise. The base layer is as shown        on <a href="#20200103">January 3</a>. Each subsequent octave is scaled        down by half in amplitude and size (doubling its frequency). Subsequent        octaves are also rotated by 2.0 radians to dis-align it with the other        layers.</p>      <pre>Brownian(0.20, Vec2(3, 5), Color(0, 1, 0), Color(0.3, 0.3, 0.3))</pre>      <img src="images/20200104_Brownian.png" alt="Brownian noise texture generator (green clouds on gray)"        title="Brownian noise texture generator (green clouds on gray)"        height="511"        width="511">    </div>    <div class="post" id="20200103"><a href="#20200103" class="date">January 3,        2020</a>      <h1>Perlin <em>Noise</em></h1>      <p>This is a <strong>TexSyn</strong> generator wrapped around the basic        Perlin <code>noise()</code> function as described in his <a href="https://mrl.nyu.edu/%7Eperlin/noise/">SIGGRAPH
          2002 paper <em>Improving Noise</em></a>. The parameters are a scale        factor, a center/translation, and two colors.</p>      <p class="designnote">(Design note: I don't like that the noise pattern is        always “axis aligned” in this formulation. I could add a rotation angle.        But I am leaning toward changing to a specification with two points (<em>Vec2</em>s)—like
        used in <em>Gradation</em>—or a point and a basis vector to specify a        whole transform: translation, rotation, and scale.)</p>      <pre>Noise(0.1, Vec2(3, 5), Color(0, 0, 1), Color(1, 1, 0))</pre>      <img src="images/20200103_Noise.png" alt="Noise texture generator (blue and yellow blobs)"        title="Noise texture generator (blue and yellow blobs)"        height="511"        width="511">    </div>    <div class="post" id="20200101"> <a href="#20200101" class="date">January        1, 2020</a>      <h1>Catching up: <em>Gradation</em>, <em>Grating</em>, <em>SoftMatte</em>,        <em>Max</em>, and <em>Min</em></h1>      <p>Having installed a modern version of <strong>OpenCV</strong> and        integrated it into <strong>TexSyn</strong>, I could now see the        textures that I had only been able to verify with unit tests so far.</p>      <h2><em>Gradation</em></h2>      <p> The <em>Gradation</em> generator defines two colored “half planes”        with a smooth (sinusoidal) transition between them. The parameters to <em>Gradation</em>        are two “colored positions.” The line segment between the two points        defines the orientation and width of the transition region. Outside the        transition region the texture is uniformly the nearest of the two        colors.</p>      <pre>Gradation(Vec2(0.4, -0.2), Color(0.9, 0.0, 0.0),          Vec2(-0.4, 0.2), Color(0.9, 0.9, 0.9));</pre>      <img src="images/20200101_Gradation.png" alt="Gradation texture generator (red to white)"        title="Gradation texture generator (red to white)"        height="511"        width="511">      <br>      <h2><em>Grating</em></h2>      <p> The <em>Grating</em> generator creates a swept stripe pattern whose        cross-sectional “slice” is a periodic waveform. The parameters to <em>Grating</em>        include: </p>      <ul>        <li>two <em>Vec2</em> positions, the endpoints of a line segment, which          define the orientation and spacing (wavelength) of the stripe pattern</li>        <li>two <em>Colors</em> for the striped pattern</li>        <li>a “softness” parameter were 0 means square wave and 1 means sine          wave (so in this example, 30% of the way from square to sinusoid).<br>        </li>      </ul>      <pre>Grating(Vec2(0.1, 0.1), Color(0, 0.8, 0),        Vec2(0.5, 0.3), Color(0.85, 0.85, 0),        0.3)</pre>      <img src="images/20200101_Grating.png" alt="Grating texture generator (green and yellow stripes)"        title="Grating texture generator (green and yellow stripes)"        height="511"        width="511">      <br>      <h2><em>SoftMatte</em></h2>      <p> The <em>SoftMatte</em> Operator take three Textures as parameters.        The first is interpreted as the “matte.” When it's luminance value is        zero, the result is taken from the second Texture. When the matte's        luminance value is one, the result is taken from the third Texture.        Matte values in between result in a linear interpolation between the        other Textures. In this example the matte Texture is a <em>Spot</em>.        The outer dark part of the <em>Spot</em> takes the second texture, a        sinusoid <em>Gradient</em> of vertical black and white bands. The inner        bright part of the spot takes the third texture, a “slightly soft square        wave” <em>Gradient</em> of horizontal magenta and blue stripes.</p>      <pre>SoftMatte(Spot(Vec2(0, 0),               0.2, Color(1, 1, 1),               0.8, Color(0, 0, 0)),          Grating(Vec2(-0.2, 0), Color(0, 0, 0),                  Vec2( 0.2, 0), Color(1, 1, 1), 1),          Grating(Vec2(0, -0.1), Color(1, 0, 1),                  Vec2(0,  0.1), Color(0, 0, 1), 0.2))</pre>      <img src="images/20200101_SoftMatte.png" alt="SoftMatte texture operator"        title="SoftMatte texture operator"        height="511"        width="511">      <br>      <h2><em>Max</em> and <em>Min</em></h2>      <p> The <em>Max</em> and <em>Min</em> operators compose two textures.        Each point's color comes from whichever input texture has the <em>Max</em>        (or <em>Min</em>) luminance/brightness at the corresponding point.        These examples show the result with the same two <em>Grating</em>s used        in the <em>SoftMatte</em> example. In the first image, the white parts        of the vertical Grating push to the front and the black parts push to        the back. They are covered by the horizontal Grating. Note that magenta        is in front of blue. The second image is the same code with <em>Min</em>        instead.</p>      <pre>Max(Grating(Vec2(-0.2, 0), Color(0, 0, 0),            Vec2( 0.2, 0), Color(1, 1, 1), 1),    Grating(Vec2(0, -0.1), Color(1, 0, 1),            Vec2(0,  0.1), Color(0, 0, 1), 0.2))</pre>      <img src="images/20200101_Max.png" alt="Max texture operator" title="Max texture operator"        height="511"        width="511">      <img src="images/20200101_Min.png" alt="Min texture operator" title="Min texture operator"        height="511"        width="511">    </div>    <div class="post" id="20191230"> <a href="#20191230" class="date">December        30, 2019</a>      <h1>“First light” and the <em>Spot</em> operator</h1>      <p>These are the first textures displayed by <strong>TexSyn</strong>        captured as screen shots. They show the result of the <em>Spot</em>        texture generator. The first one was tiny and was missing its center        constant-color region. The <strong>OpenCV</strong> utility <code>cv::imshow()</code>        is used to rasterize and display the procedural texture. The first image        used a 24 bit (three 8 bit unsigned integers) RGB representation, called        <code>CV_8UC3</code> in <strong>OpenCV</strong>. A bug caused “full        brightness” colors to wrap around to zero, causing the black center. I        fixed the bug and switched to an image format with three 32 bit floating        point number per stored pixel (<code>CV_32FC3</code>). Later I may        switch to four channel images to accommodate alpha matting. </p>      <p><strong>TexSyn</strong>'s <code>Texture</code> class supports        arbitrary resolution—so there is no static storage of pixels—all color        values are computed procedurally “on the fly” represented as three        32-bit floating point values. The <strong>OpenCV</strong> images (<code>cv::mat</code>        class) are used only at the output end, before displaying a texture on        the screen, or writing it to an image file.</p>      <p>This <em>Spot</em> Texture has been specified to be centered at the        origin, with an inner radius of 0.2 and an inner color of white. Its        outer radius is 0.6 and outer color is black. Between 0.2 and 0.6 there        is a soft sinusoidal transition between the inner and outer colors: </p>      <pre>    Spot(Vec2(0, 0),         0.2, Color(1, 1, 1),         0.6, Color(0, 0, 0));</pre>      <br>      <img src="images/20191229_first_light_crop.png" alt="“first light” image"        title="“first light” image"        height="560"        width="514">      <br>      <img src="images/20191229_Spot_crop.png" alt="texture generator Spot" title="texture generator Spot"        height="536"        width="515">    </div>    <div class="post" id="20191229"><a href="#20191229" class="date">December        29, 2019</a>      <h1>Infrastructure</h1>      <p>From December 15 through December 28 the basic infrastructure was        constructed. This included:</p>      <ul>        <li>Basic <code>c++</code> classes for <strong>Texsyn</strong>:</li>        <ul>          <li><code>Texture</code> (base class for all types of textures)</li>          <ul>            <li><code>Generator</code> (creates a texture from primitive values)</li>            <li><code>Operator</code> (combines one or more input textures (and              primitive values) to produce a new texture)</li>          </ul>          <li>Primitive values to parameter textures:</li>          <ul>            <li><code>Vec2</code> (a position on the infinite 2D texture plane)</li>            <li><code>Color</code> (very generalized representation of a point              in color space, defined as RGB values over the entire floating              point range. During texture composition, these values range over              [-∞, +∞] but are clipped to [0, 1] for display. Includes              conversion to hue/saturation/value color space and luminance.)</li>          </ul>        </ul>        <li>A <strong>Utilities</strong> package to support interpolation,          clipping, remapping, randomization, and noise.</li>        <li>A suite of <strong>unit tests</strong> to verify the correct          operation of primitives, texture generators, and operators.</li>        <li>An interface to the <strong>OpenCV</strong> library to provide:</li>        <ul>          <li>Basic utilities such as displaying rasterized textures in windows            on the screen, and writing them to standard image file formats.</li>          <li>Eventually help with implementing some operators, and particularly            to provide access to acceleration on GPU or other hardware.</li>        </ul>        <li><br>        </li>      </ul>      <p>For more details, see the <a href="https://github.com/cwreynolds/TexSyn/">code</a>        and the <a href="https://github.com/cwreynolds/TexSyn/commits/master"><code>git</code>          commit history</a>.</p>    </div>    <div class="post" id="20191219"> <a href="#20191219" class="date">December        19, 2019</a>      <h1>Designing for genetic programming</h1>      <p>Most software libraries are, of course, intended for use by human        programmers.There is a design aesthetic (“design pattern”?) that leans        toward minimal functionality (where a function should “do just one        thing”) and conversely duplication should be avoided. More complicated        patterns arise from composing the minimal units of a library.</p>      <p>In contrast, <strong>TexSyn</strong> is intended primarily for use by        a genetic programming system. GP is a type of automatic programming        technique, driven by evolutionary optimization. My experience has been        that this suggests different “best practices” for library design. This        will be revisited in future posts, but here is an example to give a        sense of this issue.</p>      <p>Imagine a texture generator called <em>Spot</em>, a disk of one color        on a field of another color. A minimalist design might define a spot        with a default diameter (say 1) at a default location (say the origin),        and a default coloring (a white spot on a black background). As such,        this minimalist <em>Spot</em> could have zero parameters. That was the        initial approach taken in 2008 for the previous version of this library.        Using standard techniques of composition of software operators, a        programmer might use a <em>Scale</em> operator to adjust the spot's        diameter, a <em>Translation</em> operator to change its position, and        perhaps a <em>Soft</em><em>Matte</em> operation to use the basic        black-and-white pattern to modulate other colors or textures. </p>      <p>This suggests a requirement for context in the composition of functions        when writing programs with this library. If we are going to call <em>Spot</em>,        we will, in general, need to surround it with calls to <em>Scale</em>,        <em>Translate</em>, etc. A human programmer would understand how to        handle this. An automated programming system would not, or at least        would need to be augmented to supply the required context. In random        programs constructed by GP, without that context, we would expect to see        a bias toward <em>Spot</em> often exhibiting its default radius and        position, because it did not happen to be modified by <em>Scale</em>, <em>Translate</em>,        etc. An alternative to declaring and maintaining this context, is to        make these transformations part of the basic <em>Spot</em> definition.        So for example <em>Spot</em> could have several parameters, such as a        center position, a radius, and the two colors to use.</p>      <p><strong>TexSyn</strong> will use this this approach, often giving        texture generators and operators additional parameters to establish        context. This makes it explicit to the genetic programming system that,        for example, a <em>Spot</em> always needs a position to be specified        because it is a required parameter to <em>Spot</em>. This removes the        need to add extra complexity related to required context. </p>    </div>    <div class="post" id="20191215"> <a href="#20191215" class="date">December        15, 2019</a>      <h1>A new library</h1>      <p>Today I created <strong><a href="https://github.com/cwreynolds/TexSyn">Texsyn</a></strong>,        a new repository on <strong>GitHub</strong>, part of a project about        adversarial evolutionary texture synthesis.</p>      <p><strong>TexSyn</strong> is a library for procedural texture synthesis.        It is intended for use by a <em>genetic programming</em> (“GP”) system,        a type of <em>genetic algorithm</em>. The GP system performs <em>simulated
          evolution</em> on a <em>population</em> of individual programs,        according to a <em>fitness function</em> (also known as a <em>fitness          metric</em>, <em>utility function</em>, or a <em>loss function</em>        in machine learning.) In this application to texture synthesis, the        programs are compositions of functions from the <strong>TexSyn</strong>        library. When executed they describe a <em>color texture</em>, an <em>image</em>.</p>      <p>This is a re-implementation and update to the <strong>TextureSynthesisTest</strong>        library as described in <a href="http://www.red3d.com/cwr/texsyn/diary.html">Texture
          Synthesis Diary</a> and used as the basis of the 2011 paper <a href="https://www.red3d.com/cwr/iec/">Interactive
          Evolution of Camouflage</a>.</p>    </div>    <div class="post" id="0">      <p>This page, and the software it describes, by <a href="https://www.red3d.com/cwr">Craig
          Reynolds</a></p>    </div>  </body></html>